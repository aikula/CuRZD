{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оглавление\n",
    "\n",
    "* [Оглавление](#1)\n",
    "\n",
    "* [Извлечение значений из текста](#2)\n",
    "\n",
    "* [Примеры решаемых задач и регулярных выражений](#3)\n",
    "\n",
    "\t* [Найти полное совпадение](#3-1)\n",
    "\n",
    "\t* [Найти цифры по шаблону](#3-2)\n",
    "\n",
    "\t* [Логическое ИЛИ](#3-3)\n",
    "\n",
    "\t* [Просмотр вперед или назад](#3-4)\n",
    "\n",
    "\t* [Другие полезные методы библиотеки Re](#3-5)\n",
    "\n",
    "\t* [Задание](#3-6)\n",
    "\n",
    "* [Библиотека Pandas](#4)\n",
    "\n",
    "\t* [Создание DataFrame](#4-1)\n",
    "\n",
    "\t* [Доступ к элементам и строкам](#4-2)\n",
    "\n",
    "\t* [Изменить значение](#4-3)\n",
    "\n",
    "\t* [Выборки ](#4-4)\n",
    "\n",
    "\t* [Сортировка](#4-5)\n",
    "\n",
    "\t* [Добавление столбцов](#4-6)\n",
    "\n",
    "\t* [Изменить значение](#4-7)\n",
    "\n",
    "\t* [Удалить строки и столбы](#4-8)\n",
    "\n",
    "\t* [Apply и Lambda](#4-9)\n",
    "\n",
    "\t* [Группировки](#4-10)\n",
    "\n",
    "\t* [Сводные таблицы](#4-11)\n",
    "\n",
    "\t* [Задание](#4-12)\n",
    "\n",
    "* [Кодирование категориальных переменных](#5)\n",
    "\n",
    "\t* [Понятие категориальных переменных](#5-1)\n",
    "\n",
    "\t* [Dummies кодирование](#5-2)\n",
    "\n",
    "\t* [Sklearn LabelEncoder](#5-3)\n",
    "\n",
    "\t* [Sklearn OneHot](#5-4)\n",
    "\n",
    "\t* [Полное преобразование](#5-5)\n",
    "\n",
    "\t* [Умные способы кодирования](#5-6)\n",
    "\n",
    "\t* [Биннинг](#5-7)\n",
    "\n",
    "\t* [Задание](#5-8)\n",
    "\n",
    "* [Проверка и подготовка данных](#6)\n",
    "\n",
    "\t* [Отбрасывание записей](#6-1)\n",
    "\n",
    "\t* [Отбрасывание признаков](#6-2)\n",
    "\n",
    "\t* [Внесение недостающих значений](#6-3)\n",
    "\n",
    "\t* [Замена недостающих значений](#6-4)\n",
    "    * [Преобразование типов](#6-5)\n",
    "\n",
    "\n",
    "# Извлечение значений из текста<a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "Последние годы языки общего назначения стали чаще использоваться для анализа данных. Разработчики и организации используют Python или Javascript для решения своих задач. И в этом им помогают регулярные выражения. Они — незаменимый инструмент для упорядочивания, причесывания, поиска или извлечения текстовых данных.\n",
    "\n",
    "Проще говоря, регулярное выражение используется для поиска паттернов в указанной строке.\n",
    "Паттерном может быть все что угодно.\n",
    "\n",
    "Можно создавать паттерны соответствия электронной почте или мобильному номеру. Можно создать паттерны, которые ищут слова в строке, начинающиеся на “a” и заканчивающиеся на “z”.\n",
    "\n",
    "Например:\n",
    "\n",
    "```python\n",
    "import re\n",
    "pattern='\\d\\d\\d'\n",
    "match = re.search(pattern, 'Номер поезда 234. Номер вагона 5') \n",
    "print(match[0] if match else 'Не найдено совпадений') #коротка форма if ... else...\n",
    "```\n",
    "\n",
    "Чаще всего регулярные выражения используются для:\n",
    "- поиска в строке;\n",
    "- разбиения строки на подстроки;\n",
    "- замены части строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регулярные выражения используют два типа символов:\n",
    "\n",
    "- специальные символы: как следует из названия, у этих символов есть специальные значения. Все специальные символы `. ˆ $ * + ? { } [ ] | ( )`;\n",
    "- литералы (например: a, b, 1, 2 и т. д.).\n",
    "\n",
    "Любая строка (в которой нет символов `.^$*+?{}[]\\|())` сама по себе является регулярным выражением. Так, выражению Хаха будет соответствовать строка “Хаха” и только она. Регулярные выражения являются регистрозависимыми, поэтому строка “хаха” (с маленькой буквы) уже не будет соответствовать выражению выше. Подобно строкам в языке Python, регулярные выражения имеют спецсимволы `.^$*+?{}[]\\|()`, которые в регулярках являются управляющими конструкциями. Для написания их просто как символов требуется их экранировать, для чего нужно поставить перед ними знак \\. Так же, как и в питоне, в регулярных выражениях выражение \\n соответствует концу строки, а \\t — табуляции.\n",
    "\n",
    "Специальные символы используются для того, чтобы искать не только полные совпадения, но и выражения согласно каким-то правилам. Например, слово должно стоять в начале строки или содержать от 5 до 10 цифр разделенных запятой. Одинаковые по своей сути паттерны можно использовать в любом методе библиотки Re.\n",
    "\n",
    "- `.`\tОдин любой символ, кроме новой строки \\n.\n",
    "- `?`\t0 или 1 вхождение шаблона слева\n",
    "- `+`\t1 и более вхождений шаблона слева\n",
    "- `*`\t0 и более вхождений шаблона слева\n",
    "- `\\w`\tЛюбая цифра или буква (\\W — все, кроме буквы или цифры)\n",
    "- `\\d`\tЛюбая цифра [0-9] (\\D — все, кроме цифры)\n",
    "- `\\s`\tЛюбой пробельный символ (\\S — любой непробельный символ)\n",
    "- `\\b`\tГраница слова\n",
    "- `[..]`\tОдин из символов в скобках ([^..] — любой символ, кроме тех, что в скобках)\n",
    "- `\\`\tЭкранирование специальных символов (\\. означает точку или \\+ — знак «плюс»)\n",
    "- `^` и `$`\tНачало и конец строки соответственно\n",
    "- `{n,m}`\tОт n до m вхождений ({,m} — от 0 до m)\n",
    "- `a|b`\tСоответствует a или b\n",
    "- `()`\tГруппирует выражение и возвращает найденный текст\n",
    "- `\\t, \\n, \\r`\tСимвол табуляции, новой строки и возврата каретки соответственно\n",
    "\n",
    "# Примеры решаемых задач и регулярных выражений<a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "Возьмем за основу текст:\n",
    "```python\n",
    "txt=\"\"\"Погрузка на сети ОАО \"Российские железные дороги\" в 2018 году, по оперативным данным, составила 1 млрд 289,6 млн тонн, что на 2,2% больше, чем за предыдущий год. Железными дорогами погружено: каменного угля – 374,9 млн тонн (+4,6% к 2017 году); кокса – 11,3 млн тонн (+0,8%); нефти и нефтепродуктов – 236,4 млн тонн (+0,4%). По оперативной информации, погрузка на сети ОАО \"РЖД\" в декабре 2018 года составила 109 млн тонн, что ниже показателя аналогичного периода предыдущего года на 1,1%. Грузооборот за декабрь 2018 года вырос к аналогичному периоду предыдущего года на 2,3% и составил 224,4 млрд тарифных тонно-км. Грузооборот с учетом пробега вагонов в порожнем состоянии за этот же период увеличился на 2,1% и составил 285,1 млрд тонно-км.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Найти полное совпадение<a class=\"anchor\" id=\"3-1\"></a>\n",
    "\n",
    "`'Российские железные дороги'` - постарается в тексте найти полное совпадение. Но если мы изменим хотя бы одну букву, совпадений не будет.\n",
    "\n",
    "## Найти цифры по шаблону<a class=\"anchor\" id=\"3-2\"></a>\n",
    "\n",
    "Например, все проценты: `'\\d{1,5}%'`. Но мы видим, что нашло только часть значений. \n",
    "\n",
    "Изменим выражение, укажем, что между цифрами может быть запятая `'\\d{1,3},\\d{1,2}%'`. \n",
    "\n",
    "Еще усилим регулярное выражение, чтобы захватывать и знак `'[-+]?\\d{1,3},\\d{1,2}%'`.\n",
    "\n",
    "Можем записать регулярное выражение и по другому `'[-+]?\\d{1,3},\\d+%'`.\n",
    "\n",
    "Это же правило можно записать и несколько в другой форме, оно проще запоминается `'[-+]?[0-9]{1,3},[0-9]+%'`.\n",
    "\n",
    "## Логическое ИЛИ<a class=\"anchor\" id=\"3-3\"></a>\n",
    "\n",
    "Например, мы хотим найти вхождение всех слов из списка:\n",
    "- тонн\n",
    "- тонно-км\n",
    "- год\n",
    "Регулярное выражение будет выглядеть так: `'тонн|тонно-км|год'`. Обратине внимание, что не верно находит вхождения. Нам надо изменить правило на `r'тонн\\b|тонно-км|год'`\n",
    "\n",
    "## Просмотр вперед или назад<a class=\"anchor\" id=\"3-4\"></a>\n",
    "\n",
    "Допустим, мы хотим выделить только то значение, которое относится к приросту кокса. Для этого будем использовать шаблоны соответсвия позиции.\n",
    "- `(?=...)`\tlookahead assertion, соответствует каждой позиции, сразу после которой начинается соответствие шаблону\n",
    "- `(?!...)`\tnegative lookahead assertion, соответствует каждой позиции, сразу после которой НЕ может начинаться шаблон \n",
    "- `(?<=...)`\tpositive lookbehind assertion, соответствует каждой позиции, которой может заканчиваться шаблон. Длина шаблона должна быть фиксированной, то есть abc и a|b — это ОК, а a* и a{2,3} — нет.\n",
    "- `(?<!...)`\tnegative lookbehind assertion, соответствует каждой позиции, которой НЕ может заканчиваться шаблон ...\n",
    "\n",
    "В нашем случае это выражение `r'(?<=кокса – )\\d+,\\d+'`.\n",
    "\n",
    "Если мы бы хотели собрать все процентные значения с учетом знака, но без значка процентов, то модифицировали бы регулярное выражение следующим образом `r'[-+]?\\d+,\\d+(?=%)'`.\n",
    "\n",
    "В качестве тренажера используйте следующий код.\n",
    "\n",
    "```python\n",
    "txt=\"\"\"Погрузка на сети ОАО \"Российские железные дороги\" в 2018 году, по оперативным данным, составила 1 млрд 289,6 млн тонн, что на 2,2% больше, чем за предыдущий год. Железными дорогами погружено: каменного угля – 374,9 млн тонн (+4,6% к 2017 году); кокса – 11,3 млн тонн (+0,8%); нефти и нефтепродуктов – 236,4 млн тонн (+0,4%). По оперативной информации, погрузка на сети ОАО \"РЖД\" в декабре 2018 года составила 109 млн тонн, что ниже показателя аналогичного периода предыдущего года на 1,1%. Грузооборот за декабрь 2018 года вырос к аналогичному периоду предыдущего года на 2,3% и составил 224,4 млрд тарифных тонно-км. Грузооборот с учетом пробега вагонов в порожнем состоянии за этот же период увеличился на 2,1% и составил 285,1 млрд тонно-км.\"\"\"\n",
    "\n",
    "pattern=r'[-+]?\\d+,\\d+(?=%)'\n",
    "match = re.findall(pattern, txt) \n",
    "if match:\n",
    "    for i in match:\n",
    "        print(i)\n",
    "else:\n",
    "    print('Ничего не найдено')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие полезные методы библиотеки Re<a class=\"anchor\" id=\"3-5\"></a>\n",
    "\n",
    "`re.match(pattern, string)`\n",
    "\n",
    "Этот метод ищет по заданному шаблону в начале строки. Например, если мы вызовем метод match() на строке «AV Analytics AV» с шаблоном «AV», то он завершится успешно. Однако если мы будем искать «Analytics», то результат будет отрицательный.\n",
    "\n",
    "`re.search(pattern, string)`\n",
    "\n",
    "Этот метод похож на match(), но он ищет не только в начале строки. В отличие от предыдущего, search() вернет объект, если мы попытаемся найти «Analytics».\n",
    "\n",
    "`re.fullmatch(pattern, string)`\n",
    "\n",
    "Проверить, подходит ли строка string под шаблон pattern\n",
    "\n",
    "`re.split(pattern, string, [maxsplit=0])`\n",
    "\n",
    "Этот метод разделяет строку по заданному шаблону.\n",
    "\n",
    "`re.sub(pattern, repl, string)`\n",
    "Этот метод ищет шаблон в строке и заменяет его на указанную подстроку. Если шаблон не найден, строка остается неизменной.\n",
    "\n",
    "```python\n",
    "import re \n",
    "\n",
    "print(re.match('\\d+', '123ilnurgi123'))\n",
    "#-> <_sre.SRE_Match object; span=(0, 3), match='123'>\n",
    "\n",
    "match = re.search(r'\\d\\d\\D\\d\\d', r'Телефон 123-12-12') \n",
    "print(match[0] if match else 'Not found') \n",
    "# -> 23-12 \n",
    "match = re.search(r'\\d\\d\\D\\d\\d', r'Телефон 1231212') \n",
    "print(match[0] if match else 'Not found') \n",
    "# -> Not found \n",
    "\n",
    "match = re.fullmatch(r'\\d\\d\\D\\d\\d', r'12-12') \n",
    "print('YES' if match else 'NO') \n",
    "# -> YES \n",
    "match = re.fullmatch(r'\\d\\d\\D\\d\\d', r'Т. 12-12') \n",
    "print('YES' if match else 'NO') \n",
    "# -> NO \n",
    "\n",
    "print(re.split(r'\\W+', 'Где, скажите мне, мои очки??!')) \n",
    "# -> ['Где', 'скажите', 'мне', 'мои', 'очки', ''] \n",
    "\n",
    "print(re.sub(r'\\d\\d\\.\\d\\d\\.\\d{4}', \n",
    "             r'DD.MM.YYYY', \n",
    "             r'Эта строка написана 19.01.2018, а могла бы и 01.09.2017')) \n",
    "# -> Эта строка написана DD.MM.YYYY, а могла бы и DD.MM.YYYY \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание<a class=\"anchor\" id=\"3-6\"></a>\n",
    "\n",
    "```python\n",
    "txt_exam=\"\"\"Число ДТП на железнодорожных переездах в 2019 году снизилось на 4 %\n",
    "Причинами дорожно-транспортных происшествий стали нарушения ПДД водителями либо неисправность автомобиля, повлекшая столкновение с проходящим подвижным составом. На железнодорожных переездах сети ОАО «Российские железные дороги» в 2019 году зафиксировано 248 дорожно-транспортных происшествий, это на 4% меньше, чем в 2018 году, сообщила пресс-служба компании.\n",
    "«Причинами ДТП стали нарушения Правил дорожного движения водителями либо неисправность автомобиля, повлекшая столкновение с проходящим подвижным составом», — говорится в сообщении.\n",
    "Наибольшее количество аварий произошло на Северо-Кавказской железной дороге (30 случаев), Московской железной дороге (33 случая) и Октябрьской магистрали (23 случая). В результате происшествий пострадали 129 человек. Для сравнения: в 2018 году на сети железных дорог произошло 259 дорожно-транспортных происшествий, в которых пострадали 175 человек.\n",
    "Ранее Gudok.ru сообщал, что количество ДТП на переездах Дальневосточной железной дороги сократилось на 35% в 2019 году.\"\"\"\n",
    "```\n",
    "\n",
    "Из текста приведенного выше:\n",
    "1. Извлеките все числа\n",
    "2. Извлеките все упоминания процентов, включая знак процентов\n",
    "3. Извлеките все числа, которые стоят рядом с упоминанием слова \"случаев\", но это слово извлекать не надо, только значение.\n",
    "4. Извлеките все числа, которые указаны в скобках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотека Pandas<a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "Pandas — это высокоуровневая библиотека Python с открытым исходным кодом, предоставляющая высокопроизводительный инструмент для обработки и анализа данных с использованием его мощных структур данных. Почему я её называю высокоуровневой, потому что построена она поверх более низкоуровневой библиотеки NumPy (написана на Си), что является большим плюсом в производительности. Название Pandas происходит от слова Panel Data — эконометрика из многомерных данных.\n",
    "\n",
    "В 2008 году разработчик Уэс МакКинни начал разработку панд, когда им нужен высокопроизводительный, гибкий инструмент для анализа данных. До Pandas Python в основном использовался для сбора и подготовки данных. Это имело очень небольшой вклад в анализ данных. Панды решили эту проблему. Используя Pandas, мы можем выполнить пять типичных шагов по обработке и анализу данных, независимо от происхождения данных: загрузить, подготовить, манипулировать, моделировать и анализировать.\n",
    "\n",
    "Ключевые особенности pandas:\n",
    "- Быстрый и эффективный объект DataFrame с индивидуальной индексацией по умолчанию.\n",
    "- Инструменты для загрузки данных в объекты данных в памяти из разных форматов файлов.\n",
    "- Выравнивание данных и интегрированная обработка отсутствующих данных.\n",
    "- Изменение формы и поворот наборов дат.\n",
    "- Метка нарезки, индексация и подмножество больших наборов данных.\n",
    "- Столбцы из структуры данных могут быть удалены или вставлены.\n",
    "- Группировка по данным для агрегации и преобразований.\n",
    "- Высокая производительность слияния и объединения данных.\n",
    "- Функциональность временных рядов.\n",
    "\n",
    "[Документация](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)\n",
    "\n",
    "Загрузка библиотеки\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание DataFrame<a class=\"anchor\" id=\"4-1\"></a>\n",
    "\n",
    "Объект DataFrame лучше всего представлять себе в виде обычной таблицы и это правильно, ведь DataFrame является табличной структурой данных. В любой таблице всегда присутствуют строки и столбцы. Столбцами в объекте DataFrame выступают объекты Series, строки которых являются их непосредственными элементами.\n",
    "\n",
    "Создадим DataFrame из обычного двухмерно списка. Воспользуемся данными о численности сотрудников и выручке крупнейших компаний.\n",
    "\n",
    "```python\n",
    "df=pd.DataFrame([['Магнит', 297460, 1237], \n",
    "                 ['X5', 278399, 1533], \n",
    "                 ['Сургутнефтегаз', 112808, 1867],\n",
    "                 ['Лукойл', 102500, 8036],\n",
    "                 ['УГМК', 80000, 165.9]])\n",
    "df # выведем результаты\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доступ к элементам и строкам<a class=\"anchor\" id=\"4-2\"></a>\n",
    "\n",
    "Обратите внимание на цифры от 0-5 слева. Это индексы, упрощенно - номера строк. 0-2 - это столбцы. Давайте дадим им названия. Чаще всего столбцы именуют латиницей.\n",
    "\n",
    "```python\n",
    "df.columns=['Company', 'Personal', 'Revenue']\n",
    "df\n",
    "```\n",
    "\n",
    "Часто удобнее использовать другие методы для отображения части DataFrame:\n",
    "- `.head()` первые пять строк (можно указать другое значение).\n",
    "- `.tail()` последние пять строк \n",
    "- `.sample()` случайные строки в указанном количестве.\n",
    "\n",
    "Чтобы получить список столбоц можно прибегнуть к внутренней переменной `df.columns`. Где `df` - это наименование таблицы.\n",
    "\n",
    "Чтобы получить список индексов воспользуемся переменной `df.index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы обратиться к DataFrame, можно использовать срезы. Точно также, как мы обращаемся к спискам.\n",
    "\n",
    "`df[0:3]`\n",
    "\n",
    "Но обратиться к одной строке так не получится.\n",
    "\n",
    "`df[1]`\n",
    "\n",
    "Для этого мы должны использовать методы `.loc[]` или `.iloc[]`\n",
    "\n",
    "```python\n",
    "print(df.loc[1])\n",
    "\n",
    "print(df.loc[1,'Company'])\n",
    "```\n",
    "\n",
    "\n",
    "Отличие методы .iloc - мы можем обращаться не по названию, а по номер столбца по порядку `df.iloc[1,2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменить значение<a class=\"anchor\" id=\"4-3\"></a>\n",
    "\n",
    "Чтобы изменить значение - надо просто обратиться к конкретной ячейке и присвоить новое значение `df.loc[1,'Company']='X5 Retail Group'`\n",
    "\n",
    "Можно обращаться не только к строкам, но и столбцам `df['Company']`\n",
    "\n",
    "Обратите внимание, что столбец - это объект типа Series. Это аналог списков, которые использует библиотека numpy. Фактически этот тип объектов ближе к словарям, так как все объекты проиндексированы и связаны с индексами.\n",
    "\n",
    "Чтобы преобразовать в тип список, надо вызвать методы array `df['Company'].array`\n",
    "\n",
    "\n",
    "Кстати, обратиться к столбцу можно и проще, не используя квадратных скобок `df.Company.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выборки <a class=\"anchor\" id=\"4-4\"></a>\n",
    "\n",
    "Легко выполнять выборки из таблицы по критериям.\n",
    "\n",
    "```python\n",
    "print(df[df['Personal']>100000])\n",
    "\n",
    "print(df[df['Personal']>100000][['Company', 'Revenue']])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или на соответствие значению.\n",
    "\n",
    "```python\n",
    "df[df['Company']=='Магнит']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если хотим вывести строки, где есть значения из списка, то используем метод `isin()`.\n",
    "\n",
    "```python\n",
    "df[df['Company'].isin(['Магнит', 'X5'])]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сортировка<a class=\"anchor\" id=\"4-5\"></a>\n",
    "\n",
    "Также есть возможность быстро и удобно делать сортировки.\n",
    "\n",
    "```python\n",
    "df.sort_values(by=['Personal'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметр ascending регулирует сортировку по убыванию или возрастанию. Также одновременно можно сортировать по нескольким столбцам.\n",
    "\n",
    "```python\n",
    "df.sort_values(by=['Personal', 'Revenue'], ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление столбцов<a class=\"anchor\" id=\"4-6\"></a>\n",
    "\n",
    "Добавить столбец очень просто. Надо просто объявить его и присвоить значение. Например, заполнить нулями.\n",
    "\n",
    "```python\n",
    "df['Temp']=0\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или вычислить значения нового столбца. Рассчитаем производительность.\n",
    "\n",
    "```python\n",
    "df['Labor']=df['Revenue']/df['Personal']\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "или присвоить значения из списка, длина которого равна длине таблицы DataFrame\n",
    "\n",
    "```python\n",
    "t_arr=[10,20,30,40,50]\n",
    "df['Temp2']=t_arr\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменить значение<a class=\"anchor\" id=\"4-7\"></a>\n",
    "\n",
    "Изменить значения столбца очень легко.\n",
    "\n",
    "```python\n",
    "df['Labor']=df['Labor']*1000000\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удалить строки и столбы<a class=\"anchor\" id=\"4-8\"></a>\n",
    "\n",
    "Также достаточно просто удалить строку или столбец. Удаляем столбец.\n",
    "\n",
    "```python\n",
    "df.drop(columns=['Temp'], inplace=True)\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А следующая команда удаляет строки.\n",
    "\n",
    "```python\n",
    "df.drop([1, 2], inplace=True)\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply и Lambda<a class=\"anchor\" id=\"4-9\"></a>\n",
    "\n",
    "Очень удобно для операций над столбцами использовать сочетание функций apply и lambda.\n",
    "\n",
    "Лябмда-выражения — это особый синтаксис в Python, необходимый для создания анонимных функций. Давайте назовем синтаксис лямбда как лямбда-выражение, а получаемую функцию — лямбда-функцию.\n",
    "\n",
    "Лямбда-выражения в Python позволяют функции быть созданной и переданной (зачастую другой функции) в одной строчке кода.\n",
    "\n",
    "Например, простая функция так:\n",
    "\n",
    "```python\n",
    "#объявим функцию\n",
    "def d100(x,y):\n",
    "    return x/y\n",
    "\n",
    "#вызовем функцию\n",
    "d100(1000,10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно объявить ее и в одну строчку, причем, часто нет необходимости присваивать ее переменной.\n",
    "\n",
    "```python\n",
    "f= lambda x,y: x/y\n",
    "f(1000,100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анонимные функции (labmbda) используют как аргумент нескольких функций - map(), filter(), reduce(), apply().\n",
    "\n",
    "`apply()` работает в Series и в качестве аргумента может принимать функции и применяет ее ко всем элементам списка.\n",
    "\n",
    "```python\n",
    "df['Revenue']=df['Revenue'].apply(lambda x: x*1000)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply() можно вызывать и к строке, обращаясь затем к элементам строки по номеру или названии. Для этого надо указать параметр axis=1.\n",
    "\n",
    "Ниже мы перемножаем два столбца между собой. \n",
    "\n",
    "```python\n",
    "df['Labor']=df.apply(lambda x:x['Revenue']/x['Personal'], axis=1)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группировки<a class=\"anchor\" id=\"4-10\"></a>\n",
    "\n",
    "DataFrame позволяет легко делать группировки.\n",
    "\n",
    "Загрузим таблицу ots_p.\n",
    "\n",
    "```python\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "                \"mysql+pymysql://root:%s@159.69.219.206:3307/rzd\" %(sql_pass), encoding='utf8', convert_unicode=True\n",
    "            )\n",
    "\n",
    "with engine.connect() as session:\n",
    "    df=pd.read_sql('SELECT * FROM ots_p LIMIT 1000', con=session)\n",
    "```\n",
    "\n",
    "**Добавим переменную sql_pass!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним агрегацию по столбцу \"Категория\" и посчитаем количество случаев по каждой категории.\n",
    "\n",
    "```python\n",
    "df.groupby([\"Категория\"])['Категория'].count()\n",
    "```\n",
    "\n",
    "К результатам можно применять следующие функции:\n",
    "- `count`\tКоличество строк\n",
    "- `sum`\tСумма\n",
    "- `mean`\tСреднее значение\n",
    "- `mad`\tСредняя абсолютное отклонение\n",
    "- `median`\tМедиана\n",
    "- `min`\tМинимум\n",
    "- `max`\tМаксимум\n",
    "- `mode`\tМода\n",
    "- `abs`\tАбсолютное значение\n",
    "- `std`\tСтандартное отклонение\n",
    "- `var`\tВариация\n",
    "- `first` Первое значение\n",
    "- `last` Последнее значение\n",
    "\n",
    "Также можно получить результат сразу по нескольким столбцам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой вариант записи позволяет выполнить над каждый столбцом свой вариант операции.\n",
    "\n",
    "```python\n",
    "df.groupby(\"Тех.средство\").agg({'Длительность':['min'], 'Категория':['median', 'count']})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда необходимо уточнить самое часто встречаемое значение. Здесь прибегаем к помощи следующей конструкции.\n",
    "\n",
    "```python\n",
    "df.groupby(\"Тех.средство\").agg({'Длительность':'min','Категория':pd.Series.mode})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сводные таблицы<a class=\"anchor\" id=\"4-11\"></a>\n",
    "\n",
    "Имеет библиотека и аналог сводных таблиц в Excel. Общий синтаксис метода:\n",
    "\n",
    "```python\n",
    "pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean')\n",
    "```\n",
    "\n",
    "Простой вариант применения сводных таблиц. Посчитаем среднюю продолжительность в разрезе типа и категории отказа. \n",
    "\n",
    "```python\n",
    "df.pivot_table(index=['Тех.средство'], columns=['Категория'], values='Длительность', aggfunc='mean')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание<a class=\"anchor\" id=\"4-12\"></a>\n",
    "\n",
    "Прочитайте 1000 строк таблицы `grdp`. \n",
    "\n",
    "На ее примере:\n",
    "- Умножьте на 10 столбец \"Продолжительность\" с использованием функции `apply()`\n",
    "- Удалите столбец \"index\"\n",
    "- Добавьте столбец с названием \"Временный\", заполните его значением 1\n",
    "- Выполните группировку по столбцу \"Дефект\" и посчитайте среднее по столбцу \"Продолжительность\"\n",
    "- Постройте сводную таблицу с индексом \"Деффект\", колонка \"Телеграмма\" и значение \"Продолжительность\". Используйте функцию нахождения среднего значения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кодирование категориальных переменных<a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "## Понятие категориальных переменных<a class=\"anchor\" id=\"5-1\"></a>\n",
    "\n",
    "Категориальные признаки называют по-разному: факторными, номинальными. Их значения определяют факт принадлежности к какой-то категории. Примеры таких признаков: пол, страна проживания, номер группы, категория товаров и т.п. Ясно, что для компьютерной обработки вместо «понятного для человека» значения (в случае страны — ‘Russia’, ‘GB’, ‘France’ и т.п.) хранят числа. \n",
    "\n",
    "Создадим для примера небольшой DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Имя':['Иван', 'Петр', 'Мария', 'Ирина'],\n",
    "                    'Пол':['М','М', 'Ж', 'Ж'], \n",
    "                    'Волосы':['Шатен', 'Блонд', 'Рыжий', 'Блонд'],\n",
    "                    'Английский':['Хорошо', 'Хорошо', 'Отлично', 'Не владеет'],\n",
    "                    'Возраст':[12, 25, 27, 33]})\n",
    "\n",
    "# удобный код, который делит на количественные и категориальные переменные\n",
    "categorical_columns = [c for c in df.columns if df[c].dtype.name == 'object']\n",
    "numerical_columns   = [c for c in df.columns if df[c].dtype.name != 'object']\n",
    "print(\"Категориальные:\", categorical_columns, \"Числовые\",numerical_columns)\n",
    "\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть количество переменных можно с помощью метода `.unique()`\n",
    "\n",
    "```python\n",
    "print(df['Пол'].unique()) #['М' 'Ж']\n",
    "\n",
    "print(df['Волосы'].unique()) #['Шатен' 'Блонд' 'Рыжий']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не только посомтреть список уникальных значений, но и посчитать их встречаемость, можно при помощи метода `value_counts()`\n",
    "\n",
    "```python\n",
    "df['Пол'].value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies кодирование<a class=\"anchor\" id=\"5-2\"></a>\n",
    "\n",
    "Способ кодирования зависит от количества уникальных значений. Если их всего два, то используем значения 0 и 1. Если больше, нужны более сложные походы.\n",
    "\n",
    "Чтобы закодировать столбец с двумя значениями подойдет метода pandas\n",
    "```python\n",
    "pd.get_dummies(df['Пол'], drop_first=True)\n",
    "```\n",
    "\n",
    "Таким же образом можем закодировать и столбец \"Волосы\". Фактически сразу добавим новые столбцы к нашей таблице.\n",
    "\n",
    "```python\n",
    "pd.get_dummies(df, columns=['Волосы'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, столбцов делают меньше чем переменных в столбце на единицу.\n",
    "\n",
    "Если цвет мы должны кодировать именно фиктивными переменными, то знание языка мы можем закодировать порядковыми номерами. Поясню: если цвет волос \"Шатен\" закодирован номером 0, \"Блонд\" - 2, \"Рыжий\" - 3, то это ошибка, так как это разные цвета. Между \"Блонд\" и \"Шатен\" расстояние не больше, чем между \"Блонд\" и \"Рыжий\". А вот между знанием хорошо и отлично английского языка действительно может быть меньше, чем полное незнание языка и отличное им владение.\n",
    "\n",
    "Можно использовать метод factorize: он автоматически сформирует список, который можно использовать как значения столбца.\n",
    "\n",
    "```python\n",
    "print(pd.factorize(df['Английский'])[0])\n",
    "print(pd.factorize(df['Английский'])[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn LabelEncoder<a class=\"anchor\" id=\"5-3\"></a>\n",
    "\n",
    "Описанный выше подход хорош если нам не надо делить выборку на тестовую и обучающую. В противном случае, мы фактически получаем \"утечку\" информации из тестового набора. А также возникают сложности с кодированием новых данных. В этом случае применим методы из библиотеки `sklearn `. Посмотрим вначале на более простой вариант, кодирование через метки.\n",
    "\n",
    "[Документация](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder() #создаем объект\n",
    "#тренируем и сразу преобразовываем. Могут быть и последовательные операции\n",
    "label_encoded_data = label_encoder.fit_transform(df['Английский']) \n",
    "\n",
    "print(label_encoded_data) #[2 2 1 0]\n",
    "#закодируем новые данные\n",
    "print(label_encoder.transform(['Хорошо', 'Отлично'])) #[2 1]\n",
    "#обратное преобразование\n",
    "print(label_encoder.inverse_transform(label_encoded_data)) #['Хорошо' 'Хорошо' 'Отлично' 'Не владеет']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn OneHot<a class=\"anchor\" id=\"5-4\"></a>\n",
    "\n",
    "Аналогичным образом выполним dummy кодирование. Единственное, что мы можем кодировать сразу несколько столбцов.\n",
    "\n",
    "[Документация](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder() #объект класса\n",
    "#преобразуем\n",
    "x = onehotencoder.fit_transform(df[['Английский', \"Волосы\"]]).toarray()\n",
    "print(x) \n",
    "#выполним преобразование новых данных\n",
    "print(onehotencoder.transform([['Хорошо', 'Шатен']]).toarray()) #[[0. 0. 1. 0. 0. 1.]]\n",
    "#получим уникальные значения категорий\n",
    "print(onehotencoder.categories_)\n",
    "#выполним обратное преобразование\n",
    "print(onehotencoder.inverse_transform([[0, 0, 1, 0, 0, 1]]))\n",
    "#получим названия столбцов\n",
    "print(onehotencoder.get_feature_names(['Английский','Волосы']))\n",
    "```\n",
    "\n",
    "При создании объекта класса можно передать следующие параметры:\n",
    "- `handle_unknown='ignore'` - игнорировать при преобразовании неизвестные значения\n",
    "- `drop='first'` - удалить первый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полное преобразование<a class=\"anchor\" id=\"5-5\"></a>\n",
    "\n",
    "Полный код преобразования для нашего примера может выглядеть следующим образом.\n",
    "```python\n",
    "onehotencoder = OneHotEncoder(drop='first')\n",
    "x = onehotencoder.fit_transform(df[[\"Пол\", \"Английский\", \"Волосы\"]]).toarray()\n",
    "col=onehotencoder.get_feature_names([\"Пол\", \"Английский\", \"Волосы\"])\n",
    "df_data=pd.DataFrame(x, columns=col) #создадим новый DataFrame\n",
    "df_data['Возраст']=df['Возраст'] #добавим столбец с возрастом из оригинальной таблицы\n",
    "df_data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Умные способы кодирования<a class=\"anchor\" id=\"5-6\"></a>\n",
    "\n",
    "Когда не хотят заполонять признаковую матрицу кучей бинарных признаков, применяют кодировки, в которых категории кодируются какими-то интерпретируемыми значениями. Например, если это категория товаров в интернет-магазине, то логично её закодировать средней ценой товара. Тогда, по крайней мере, наш новый признак упорядочивает категории по дороговизне. В любом случае, делается это с помощью функции map и groupby. Кстати, даже если бы функции map не было, можно было бы обойтись выражением `data[feature].apply(lambda x: dct[x])`\n",
    "\n",
    "Самый примитивный способ кодирования — заменить каждую категорию числом входящих в неё объектов (т.е. знания других признаков вообще не нужно). Это делается в одну строчку кода: `data[newfeature] = data[feature].map(data.groupby(feature).size())`.\n",
    "\n",
    "## Биннинг<a class=\"anchor\" id=\"5-7\"></a>\n",
    "\n",
    "Биннинг или объединение данных - это метод предварительной обработки данных, используемый для уменьшения влияния незначительных ошибок наблюдения. Исходные значения данных, попадающие в заданный небольшой интервал (бин), заменяются значением, представляющим этот интервал, часто центральным значением. Это форма квантования.\n",
    "\n",
    "Ниже простая техника для разделения на группы.\n",
    "\n",
    "```python\n",
    "bins = [0, 10, 20, 30, 40] #границы классов\n",
    "labels = [1,2,3, 4] # меток на одну меньше, чем границ корзин\n",
    "#добавим столбец\n",
    "df['binned'] = pd.cut(df['Возраст'], bins=bins, labels=labels) \n",
    "print (df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание<a class=\"anchor\" id=\"5-8\"></a>\n",
    "\n",
    "Загрузите 1000 строк таблицы `grdp`, закодировать OneHotEncoder столбцы:\n",
    "- Регион\n",
    "- Тип виновного предприятия\n",
    "- Вид работ.\n",
    "\n",
    "Закодировать LabelEncoder столбец \"статус события\".\n",
    "\n",
    "Создать новый DataFrame с данными и добавить столбец \"Итоговый суммарный ущерб (тыс.руб.)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка и подготовка данных<a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "Одна из самых трудоемких задачи при анализе, это первичная подготовка данных. Где нам надо решить целый комплекс задач:\n",
    "- проблема пропусков\n",
    "- оценить значимость информации\n",
    "- выполнить кодирование\n",
    "- провести первичный разведовательный анализ данных.\n",
    "\n",
    "В этой задаче будем работать с набором данных ku_asrb.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "                \"mysql+pymysql://root:%s@159.69.219.206:3307/rzd\" %(sql_pass), encoding='utf8', convert_unicode=True\n",
    "            )\n",
    "\n",
    "with engine.connect() as session:\n",
    "    df=pd.read_sql('SELECT * FROM ku_asrb LIMIT 1000', con=session)\n",
    "    \n",
    "df.sample(4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Команды `df.info()` позволит получить первчиную информацию о датасете: `1000 non-null int64`. Первое число это количество не нулевых значений (non-null), а int64 тип значения поля.\n",
    "\n",
    "Для учебного примера будем использовать только часть данных (столбцов).\n",
    "\n",
    "```python\n",
    "col=['Уникальный идентификатор события (внутри дороги)',\n",
    "       'Код дороги', 'Статус события', 'Дата события',\n",
    "       'Дата создания события в системе AC PБ', 'Тип виновного предприятия',\n",
    "       'Функциональный филиал', 'Региональный центр',\n",
    "       'Количество задержанных поездов',\n",
    "       'Размер возмещенного ущерба (тыс.руб.)',\n",
    "       'Итоговый суммарный ущерб (тыс.руб.)']\n",
    "df=df[col]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество пропусков по столбцам. На это удобно взглянуть как при помощи диаграммы, так и вывести статистику. Сам код мы изучим подробно чуть позже. Пока важнее результат.\n",
    "\n",
    "```python\n",
    "#загрузим библиотеки, которые отвечают за отрисовку графиков\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.pyplot import figure\n",
    "#выводить график сразу после ячейки с кодом\n",
    "%matplotlib inline \n",
    "matplotlib.rcParams['figure.figsize'] = (12,8) #установим размер графика\n",
    "sns.heatmap(df.isnull());\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посчитаем процент пропусков.\n",
    "\n",
    "```python\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что делать с пропущенными значениями<a class=\"anchor\" id=\"6-1\"></a>\n",
    "\n",
    "Не существует общих решений для проблемы отсутствующих данных. Для каждого конкретного набора приходится искать наиболее подходящие методы или их комбинации.\n",
    "\n",
    "Разберем четыре самых распространенных техники. Они помогут в простых ситуациях, но, скорее всего, придется проявить творческий подход и поискать нетривиальные решения, например, промоделировать пропуски.\n",
    "\n",
    "## Отбрасывание записей\n",
    "\n",
    "Первая техника в статистике называется методом удаления по списку и заключается в простом отбрасывании записи, содержащей пропущенные значения. Это решение подходит только в том случае, если недостающие данные не являются информативными.\n",
    "\n",
    "```python\n",
    "df.dropna(axis='index', how='any') #чтобы применить изменения, добавить в скобки inplace=True\n",
    "```\n",
    "\n",
    "Также можно использовать параметр `how='all'` - будет удалять только пустые строки. А также `thresh=int` - требуется не менее какого-то количества не нулевых значений. `subset` принимает список столбцов, которые надо включить в анализ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбрасывание признаков<a class=\"anchor\" id=\"6-2\"></a>\n",
    "\n",
    "Как и предыдущая техника, отбрасывание признаков может применяться только для неинформативных признаков.\n",
    "\n",
    "```python\n",
    "df.dropna(axis='columns', how='any')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Внесение недостающих значений<a class=\"anchor\" id=\"6-3\"></a>\n",
    "\n",
    "Для численных признаков можно воспользоваться методом принудительного заполнения пропусков. Например, на место пропуска можно записать среднее или медианное значение, полученное из остальных записей.\n",
    "\n",
    "Для категориальных признаков можно использовать в качестве заполнителя наиболее часто встречающееся значение.\n",
    "\n",
    "Изучим частоту встречаемости значений.\n",
    "\n",
    "```python\n",
    "df['Функциональный филиал'].value_counts()\n",
    "```\n",
    "\n",
    "Проведем замену.\n",
    "\n",
    "```python\n",
    "df['Функциональный филиал'].fillna('ЦДИ ОАО \"РЖД\"', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Замена недостающих значений<a class=\"anchor\" id=\"6-4\"></a>\n",
    "\n",
    "Можно использовать некоторый дефолтный плейсхолдер для пропусков, например, новую категорию _MISSING_ для категориальных признаков или число -999 для числовых.\n",
    "\n",
    "Таким образом, мы сохраняем данные о пропущенных значениях, что тоже может быть ценной информацией.\n",
    "\n",
    "```python\n",
    "df['Региональный центр'].fillna('_MISSING_', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование типов<a class=\"anchor\" id=\"6-5\"></a>\n",
    "\n",
    "Изучая образцы данных, мы видим, что числа обозначены как нечисловые значения. В этих случаях важно выполнить приведение типов. Но рекомендуется это делать только после заполнения пропусков.\n",
    "\n",
    "Проще всего выполнить преобразование с использованием метода `.astype()`\n",
    "\n",
    "```python\n",
    "df['Итоговый суммарный ущерб (тыс.руб.)']=df['Итоговый суммарный ущерб (тыс.руб.)'].astype(float)\n",
    "```\n",
    "\n",
    "Но он выдаст исключение, так как не сможет преобразовать некоторые значения. Можно было бы использовать параметр `errors=‘ignore’`, но проблемы бы появились позже. Исследуем ситуацию.\n",
    "\n",
    "```python\n",
    "s=[]\n",
    "for i in df['Итоговый суммарный ущерб (тыс.руб.)'].array:\n",
    "    try:\n",
    "        z=float(i)\n",
    "    except:\n",
    "        s.append(i)\n",
    "print(set(s))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что часть значений ошибочны. Нам надо их заменить на нули (или удалить), фактически это пропуски. А затем выполнить преобразование типа.\n",
    "\n",
    "```python\n",
    "df.loc[df['Итоговый суммарный ущерб (тыс.руб.)']=='.', 'Итоговый суммарный ущерб (тыс.руб.)']='0'\n",
    "df['Итоговый суммарный ущерб (тыс.руб.)']=df['Итоговый суммарный ущерб (тыс.руб.)'].astype(float)\n",
    "```\n",
    "\n",
    "Тоже самое проделаем со столбцом \"Размер возмещенного ущерба (тыс.руб.)\".\n",
    "\n",
    "Со столбцом \"Количество задержанных поездов\" несколько сложнее. Мы видим, что время можно преобразовать в секунды для удобства анализа. Или в другой формат времени. \n",
    "\n",
    "Напишем небольшую вспомогательную функцию.\n",
    "\n",
    "```python\n",
    "def time_to_sec(s):\n",
    "    s3=s.split(':')\n",
    "    if len(s3)<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(s3[0])*60*60+int(s3[1])*60+int(s3[2])\n",
    "    \n",
    "df['Количество задержанных поездов']=df['Количество задержанных поездов'].apply(lambda x: time_to_sec(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть еще два столбца с датами \"Дата события\" и \"Дата создания события в системе AC PБ\". Здесь нам придется \"разобрать\" строку в дату по шаблону.\n",
    "\n",
    "```python\n",
    "df['Дата события']=df['Дата события'].apply(lambda x: pd.to_datetime(x, format='%d%b%Y:%H:%M:%S'))\n",
    "```\n",
    "\n",
    "Получим ошибку, так как не все строки введены корректно. Придется также написать небольшую функцию.\n",
    "\n",
    "```python\n",
    "def ddate(s):\n",
    "    try:\n",
    "        res=pd.to_datetime(s, format='%d%b%Y:%H:%M:%S')\n",
    "    except:\n",
    "        res=np.NaN\n",
    "    return res\n",
    "df['Дата события']=df['Дата события'].apply(lambda x: ddate(x))\n",
    "```\n",
    "\n",
    "[Инструкция по формату](https://www.programiz.com/python-programming/datetime/strptime)\n",
    "\n",
    "Посмотрим, в каких строках не смогло произойти преобразование.\n",
    "\n",
    "```python\n",
    "df[df['Дата события'].isna()]\n",
    "```\n",
    "\n",
    "Удалим эти строки и проделаем операцию преобразования со столбцом \"Дата создания события в системе AC PБ\"\n",
    "\n",
    "```python\n",
    "df.drop(df[df['Дата события'].isna()].index, axis='index', inplace=True)\n",
    "df['Дата создания события в системе AC PБ']=df['Дата создания события в системе AC PБ'].apply(lambda x: ddate(x))\n",
    "df[df['Дата события'].isna()]\n",
    "```\n",
    "\n",
    "А также можем создать новый признак, это количество времени в секундах между временем события и его регистрацией.\n",
    "\n",
    "```python\n",
    "df['Время до регистрации']=df.apply(lambda x:(x['Дата создания события в системе AC PБ']-x['Дата события']).total_seconds(), axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание<a name=\"i18\"></a>\n",
    "\n",
    "Загрузите 1000 строк таблицы ku_asutnbd. Проведите преобразование и очистку данных по столбцам `'Дата нарушения', 'Дата расшифровки', 'Скорость фактич', 'Начальный км', 'Путь', 'Вес'`.\n",
    "\n",
    "А именно, отработайте по пропущенным значениям:\n",
    "- удаление\n",
    "- замену\n",
    "\n",
    "Преобразуйте в даты и числовой формат столбцы. Учтите, что сменился шаблон даты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
