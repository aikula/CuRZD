{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлечение значений из текста\n",
    "\n",
    "Последние годы языки общего назначения стали чаще использоваться для анализа данных. Разработчики и организации используют Python или Javascript для решения своих задач. И в этом им помогают регулярные выражения. Они — незаменимый инструмент для упорядочивания, причесывания, поиска или извлечения текстовых данных.\n",
    "\n",
    "Проще говоря, регулярное выражение используется для поиска паттернов в указанной строке.\n",
    "Паттерном может быть все что угодно.\n",
    "\n",
    "Можно создавать паттерны соответствия электронной почте или мобильному номеру. Можно создать паттерны, которые ищут слова в строке, начинающиеся на “a” и заканчивающиеся на “z”.\n",
    "\n",
    "Например:\n",
    "\n",
    "```python\n",
    "import re\n",
    "pattern='\\d\\d\\d'\n",
    "match = re.search(pattern, 'Номер поезда 234. Номер вагона 5') \n",
    "print(match[0] if match else 'Не найдено совпадений') #коротка форма if ... else...\n",
    "```\n",
    "\n",
    "Чаще всего регулярные выражения используются для:\n",
    "- поиска в строке;\n",
    "- разбиения строки на подстроки;\n",
    "- замены части строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регулярные выражения используют два типа символов:\n",
    "\n",
    "- специальные символы: как следует из названия, у этих символов есть специальные значения. Все специальные символы `. ˆ $ * + ? { } [ ] | ( )`;\n",
    "- литералы (например: a, b, 1, 2 и т. д.).\n",
    "\n",
    "Любая строка (в которой нет символов `.^$*+?{}[]\\|())` сама по себе является регулярным выражением. Так, выражению Хаха будет соответствовать строка “Хаха” и только она. Регулярные выражения являются регистрозависимыми, поэтому строка “хаха” (с маленькой буквы) уже не будет соответствовать выражению выше. Подобно строкам в языке Python, регулярные выражения имеют спецсимволы `.^$*+?{}[]\\|()`, которые в регулярках являются управляющими конструкциями. Для написания их просто как символов требуется их экранировать, для чего нужно поставить перед ними знак \\. Так же, как и в питоне, в регулярных выражениях выражение \\n соответствует концу строки, а \\t — табуляции.\n",
    "\n",
    "Специальные символы используются для того, чтобы искать не только полные совпадения, но и выражения согласно каким-то правилам. Например, слово должно стоять в начале строки или содержать от 5 до 10 цифр разделенных запятой. Одинаковые по своей сути паттерны можно использовать в любом методе библиотки Re.\n",
    "\n",
    "- `.`\tОдин любой символ, кроме новой строки \\n.\n",
    "- `?`\t0 или 1 вхождение шаблона слева\n",
    "- `+`\t1 и более вхождений шаблона слева\n",
    "- `*`\t0 и более вхождений шаблона слева\n",
    "- `\\w`\tЛюбая цифра или буква (\\W — все, кроме буквы или цифры)\n",
    "- `\\d`\tЛюбая цифра [0-9] (\\D — все, кроме цифры)\n",
    "- `\\s`\tЛюбой пробельный символ (\\S — любой непробельный символ)\n",
    "- `\\b`\tГраница слова\n",
    "- `[..]`\tОдин из символов в скобках ([^..] — любой символ, кроме тех, что в скобках)\n",
    "- `\\`\tЭкранирование специальных символов (\\. означает точку или \\+ — знак «плюс»)\n",
    "- `^` и `$`\tНачало и конец строки соответственно\n",
    "- `{n,m}`\tОт n до m вхождений ({,m} — от 0 до m)\n",
    "- `a|b`\tСоответствует a или b\n",
    "- `()`\tГруппирует выражение и возвращает найденный текст\n",
    "- `\\t, \\n, \\r`\tСимвол табуляции, новой строки и возврата каретки соответственно\n",
    "\n",
    "## Примеры решаемых задач и регулярных выражений\n",
    "\n",
    "Возьмем за основу текст:\n",
    "```python\n",
    "txt=\"\"\"Погрузка на сети ОАО \"Российские железные дороги\" в 2018 году, по оперативным данным, составила 1 млрд 289,6 млн тонн, что на 2,2% больше, чем за предыдущий год. Железными дорогами погружено: каменного угля – 374,9 млн тонн (+4,6% к 2017 году); кокса – 11,3 млн тонн (+0,8%); нефти и нефтепродуктов – 236,4 млн тонн (+0,4%). По оперативной информации, погрузка на сети ОАО \"РЖД\" в декабре 2018 года составила 109 млн тонн, что ниже показателя аналогичного периода предыдущего года на 1,1%. Грузооборот за декабрь 2018 года вырос к аналогичному периоду предыдущего года на 2,3% и составил 224,4 млрд тарифных тонно-км. Грузооборот с учетом пробега вагонов в порожнем состоянии за этот же период увеличился на 2,1% и составил 285,1 млрд тонно-км.\"\"\"\n",
    "```\n",
    "\n",
    "### Найти полное совпадение\n",
    "\n",
    "`'Российские железные дороги'` - постарается в тексте найти полное совпадение. Но если мы изменим хотя бы одну букву, совпадений не будет.\n",
    "\n",
    "### Найти цифры по шаблону\n",
    "\n",
    "Например, все проценты: `'\\d{1,5}%'`. Но мы видим, что нашло только часть значений. \n",
    "\n",
    "Изменим выражение, укажем, что между цифрами может быть запятая `'\\d{1,3},\\d{1,2}%'`. \n",
    "\n",
    "Еще усилим регулярное выражение, чтобы захватывать и знак `'[-+]?\\d{1,3},\\d{1,2}%'`.\n",
    "\n",
    "Можем записать регулярное выражение и по другому `'[-+]?\\d{1,3},\\d+%'`.\n",
    "\n",
    "Это же правило можно записать и несколько в другой форме, оно проще запоминается `'[-+]?[0-9]{1,3},[0-9]+%'`.\n",
    "\n",
    "### Логическое ИЛИ\n",
    "\n",
    "Например, мы хотим найти вхождение всех слов из списка:\n",
    "- тонн\n",
    "- тонно-км\n",
    "- год\n",
    "Регулярное выражение будет выглядеть так: `'тонн|тонно-км|год'`. Обратине внимание, что не верно находит вхождения. Нам надо изменить правило на `r'тонн\\b|тонно-км|год'`\n",
    "\n",
    "### Просмотр вперед или назад\n",
    "\n",
    "Допустим, мы хотим выделить только то значение, которое относится к приросту кокса. Для этого будем использовать шаблоны соответсвия позиции.\n",
    "- `(?=...)`\tlookahead assertion, соответствует каждой позиции, сразу после которой начинается соответствие шаблону\n",
    "- `(?!...)`\tnegative lookahead assertion, соответствует каждой позиции, сразу после которой НЕ может начинаться шаблон \n",
    "- `(?<=...)`\tpositive lookbehind assertion, соответствует каждой позиции, которой может заканчиваться шаблон. Длина шаблона должна быть фиксированной, то есть abc и a|b — это ОК, а a* и a{2,3} — нет.\n",
    "- `(?<!...)`\tnegative lookbehind assertion, соответствует каждой позиции, которой НЕ может заканчиваться шаблон ...\n",
    "\n",
    "В нашем случае это выражение `r'(?<=кокса – )\\d+,\\d+'`.\n",
    "\n",
    "Если мы бы хотели собрать все процентные значения с учетом знака, но без значка процентов, то модифицировали бы регулярное выражение следующим образом `r'[-+]?\\d+,\\d+(?=%)'`.\n",
    "\n",
    "В качестве тренажера используйте следующий код.\n",
    "\n",
    "```python\n",
    "txt=\"\"\"Погрузка на сети ОАО \"Российские железные дороги\" в 2018 году, по оперативным данным, составила 1 млрд 289,6 млн тонн, что на 2,2% больше, чем за предыдущий год. Железными дорогами погружено: каменного угля – 374,9 млн тонн (+4,6% к 2017 году); кокса – 11,3 млн тонн (+0,8%); нефти и нефтепродуктов – 236,4 млн тонн (+0,4%). По оперативной информации, погрузка на сети ОАО \"РЖД\" в декабре 2018 года составила 109 млн тонн, что ниже показателя аналогичного периода предыдущего года на 1,1%. Грузооборот за декабрь 2018 года вырос к аналогичному периоду предыдущего года на 2,3% и составил 224,4 млрд тарифных тонно-км. Грузооборот с учетом пробега вагонов в порожнем состоянии за этот же период увеличился на 2,1% и составил 285,1 млрд тонно-км.\"\"\"\n",
    "\n",
    "pattern=r'[-+]?\\d+,\\d+(?=%)'\n",
    "match = re.findall(pattern, txt) \n",
    "if match:\n",
    "    for i in match:\n",
    "        print(i)\n",
    "else:\n",
    "    print('Ничего не найдено')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие полезные методы библиотеки Re\n",
    "\n",
    "`re.match(pattern, string)`\n",
    "\n",
    "Этот метод ищет по заданному шаблону в начале строки. Например, если мы вызовем метод match() на строке «AV Analytics AV» с шаблоном «AV», то он завершится успешно. Однако если мы будем искать «Analytics», то результат будет отрицательный.\n",
    "\n",
    "`re.search(pattern, string)`\n",
    "\n",
    "Этот метод похож на match(), но он ищет не только в начале строки. В отличие от предыдущего, search() вернет объект, если мы попытаемся найти «Analytics».\n",
    "\n",
    "`re.fullmatch(pattern, string)`\n",
    "\n",
    "Проверить, подходит ли строка string под шаблон pattern\n",
    "\n",
    "`re.split(pattern, string, [maxsplit=0])`\n",
    "\n",
    "Этот метод разделяет строку по заданному шаблону.\n",
    "\n",
    "`re.sub(pattern, repl, string)`\n",
    "Этот метод ищет шаблон в строке и заменяет его на указанную подстроку. Если шаблон не найден, строка остается неизменной.\n",
    "\n",
    "```python\n",
    "import re \n",
    "\n",
    "print(re.match('\\d+', '123ilnurgi123'))\n",
    "#-> <_sre.SRE_Match object; span=(0, 3), match='123'>\n",
    "\n",
    "match = re.search(r'\\d\\d\\D\\d\\d', r'Телефон 123-12-12') \n",
    "print(match[0] if match else 'Not found') \n",
    "# -> 23-12 \n",
    "match = re.search(r'\\d\\d\\D\\d\\d', r'Телефон 1231212') \n",
    "print(match[0] if match else 'Not found') \n",
    "# -> Not found \n",
    "\n",
    "match = re.fullmatch(r'\\d\\d\\D\\d\\d', r'12-12') \n",
    "print('YES' if match else 'NO') \n",
    "# -> YES \n",
    "match = re.fullmatch(r'\\d\\d\\D\\d\\d', r'Т. 12-12') \n",
    "print('YES' if match else 'NO') \n",
    "# -> NO \n",
    "\n",
    "print(re.split(r'\\W+', 'Где, скажите мне, мои очки??!')) \n",
    "# -> ['Где', 'скажите', 'мне', 'мои', 'очки', ''] \n",
    "\n",
    "print(re.sub(r'\\d\\d\\.\\d\\d\\.\\d{4}', \n",
    "             r'DD.MM.YYYY', \n",
    "             r'Эта строка написана 19.01.2018, а могла бы и 01.09.2017')) \n",
    "# -> Эта строка написана DD.MM.YYYY, а могла бы и DD.MM.YYYY \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "```python\n",
    "txt_exam=\"\"\"Число ДТП на железнодорожных переездах в 2019 году снизилось на 4 %\n",
    "Причинами дорожно-транспортных происшествий стали нарушения ПДД водителями либо неисправность автомобиля, повлекшая столкновение с проходящим подвижным составом. На железнодорожных переездах сети ОАО «Российские железные дороги» в 2019 году зафиксировано 248 дорожно-транспортных происшествий, это на 4% меньше, чем в 2018 году, сообщила пресс-служба компании.\n",
    "«Причинами ДТП стали нарушения Правил дорожного движения водителями либо неисправность автомобиля, повлекшая столкновение с проходящим подвижным составом», — говорится в сообщении.\n",
    "Наибольшее количество аварий произошло на Северо-Кавказской железной дороге (30 случаев), Московской железной дороге (33 случая) и Октябрьской магистрали (23 случая). В результате происшествий пострадали 129 человек. Для сравнения: в 2018 году на сети железных дорог произошло 259 дорожно-транспортных происшествий, в которых пострадали 175 человек.\n",
    "Ранее Gudok.ru сообщал, что количество ДТП на переездах Дальневосточной железной дороги сократилось на 35% в 2019 году.\"\"\"\n",
    "```\n",
    "\n",
    "Из текста приведенного выше:\n",
    "1. Извлеките все числа\n",
    "2. Извлеките все упоминания процентов, включая знак процентов\n",
    "3. Извлеките все числа, которые стоят рядом с упоминанием слова \"случаев\", но это слово извлекать не надо, только значение.\n",
    "4. Извлеките все числа, которые указаны в скобках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотека Pandas\n",
    "\n",
    "Pandas — это высокоуровневая библиотека Python с открытым исходным кодом, предоставляющая высокопроизводительный инструмент для обработки и анализа данных с использованием его мощных структур данных. Почему я её называю высокоуровневой, потому что построена она поверх более низкоуровневой библиотеки NumPy (написана на Си), что является большим плюсом в производительности. Название Pandas происходит от слова Panel Data — эконометрика из многомерных данных.\n",
    "\n",
    "В 2008 году разработчик Уэс МакКинни начал разработку панд, когда им нужен высокопроизводительный, гибкий инструмент для анализа данных. До Pandas Python в основном использовался для сбора и подготовки данных. Это имело очень небольшой вклад в анализ данных. Панды решили эту проблему. Используя Pandas, мы можем выполнить пять типичных шагов по обработке и анализу данных, независимо от происхождения данных: загрузить, подготовить, манипулировать, моделировать и анализировать.\n",
    "\n",
    "Ключевые особенности pandas:\n",
    "- Быстрый и эффективный объект DataFrame с индивидуальной индексацией по умолчанию.\n",
    "- Инструменты для загрузки данных в объекты данных в памяти из разных форматов файлов.\n",
    "- Выравнивание данных и интегрированная обработка отсутствующих данных.\n",
    "- Изменение формы и поворот наборов дат.\n",
    "- Метка нарезки, индексация и подмножество больших наборов данных.\n",
    "- Столбцы из структуры данных могут быть удалены или вставлены.\n",
    "- Группировка по данным для агрегации и преобразований.\n",
    "- Высокая производительность слияния и объединения данных.\n",
    "- Функциональность временных рядов.\n",
    "\n",
    "[Документация](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)\n",
    "\n",
    "Загрузка библиотеки\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "Объект DataFrame лучше всего представлять себе в виде обычной таблицы и это правильно, ведь DataFrame является табличной структурой данных. В любой таблице всегда присутствуют строки и столбцы. Столбцами в объекте DataFrame выступают объекты Series, строки которых являются их непосредственными элементами.\n",
    "\n",
    "Создадим DataFrame из обычного двухмерно списка. Воспользуемся данными о численности сотурдников и выручке крупнейших компаний.\n",
    "\n",
    "```python\n",
    "df=pd.DataFrame([['Магнит', 297460, 1237], \n",
    "                 ['X5', 278399, 1533], \n",
    "                 ['Сургутнефтегаз', 112808, 1867],\n",
    "                 ['Лукойл', 102500, 8036],\n",
    "                 ['УГМК', 80000, 165.9]])\n",
    "df # выведем результаты\n",
    "```\n",
    "\n",
    "Обратите внимание на цифры от 0-5 слева. Это индексы, упрощенно - номера строк. 0-2 - это столбцы. Давайте дадим им названия. Чаще всего столбцы именуют латиницей.\n",
    "\n",
    "```python\n",
    "df.columns=['Company', 'Personal', 'Revenue']\n",
    "df\n",
    "```\n",
    "\n",
    "Часто удобнее использовать другие методы для отображения части DataFrame:\n",
    "- `.head()` первые пять строк (можно указать другое значение).\n",
    "- `.tail()` последние пять строк \n",
    "- `.sample()` случайные строки в указанном количестве.\n",
    "\n",
    "Чтобы получить список столбоц можно прибегнуть к внутренней переменной `df.columns`. Где `df` - это наименование таблицы.\n",
    "\n",
    "Чтобы получить список индексов воспользуемся переменной `df.index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы обратиться к DataFrame, можно использовать срезы. Точно также, как мы обращаемся к спискам.\n",
    "\n",
    "`df[0:3]`\n",
    "\n",
    "Но обратиться к одной строке так не получится.\n",
    "\n",
    "`df[1]`\n",
    "\n",
    "Для этого мы должны использовать методы `.loc[]` или `.iloc[]`\n",
    "\n",
    "```python\n",
    "print(df.loc[1])\n",
    "\n",
    "print(df.loc[1,'Company'])\n",
    "```\n",
    "\n",
    "\n",
    "Отличие методы .iloc - мы можем обращаться не по названию, а по номер столбца по порядку `df.iloc[1,2]`\n",
    "\n",
    "Чтобы изменить значение - надо просто обратиться к конретной ячейке и присвоить новое значение `df.loc[1,'Company']='X5 Retail Group'`\n",
    "\n",
    "Можно обращаться не только к строкам, но и столбцам `df['Company']`\n",
    "\n",
    "Обратите внимание, что столбец - это объект типа Series. Это аналог списков, которые использует библиотека numpy. Фактически этот тип объектов ближе к словарям, так как все объекты проиндексированы и связаны с индексами.\n",
    "\n",
    "Чтобы преобразовать в тип список, надо вызвать методы array `df['Company'].array`\n",
    "\n",
    "\n",
    "Кстати, обратиться к столбцу можно и проще, не используя квадратных скобок `df.Company.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Легко выполнять выборки из таблицы по критериям.\n",
    "\n",
    "```python\n",
    "print(df[df['Personal']>100000])\n",
    "\n",
    "print(df[df['Personal']>100000][['Company', 'Revenue']])\n",
    "```\n",
    "\n",
    "Добавить столбец очень просто. Надо просто объявить его и присвоить значение. Например, заполнить нулями.\n",
    "\n",
    "```python\n",
    "df['Temp']=0\n",
    "df\n",
    "```\n",
    "\n",
    "Или вычислить значения нового столбца. Расчитаем производительность.\n",
    "\n",
    "```python\n",
    "df['Labor']=df['Revenue']/df['Personal']\n",
    "df\n",
    "```\n",
    "\n",
    "или присвоить значения из списка, длина которого равна длине таблицы DataFrame\n",
    "\n",
    "```python\n",
    "t_arr=[10,20,30,40,50]\n",
    "df['Temp2']=t_arr\n",
    "df\n",
    "```\n",
    "\n",
    "Изменить значения столца очень легко.\n",
    "\n",
    "```python\n",
    "df['Labor']=df['Labor']*1000000\n",
    "df\n",
    "```\n",
    "\n",
    "\n",
    "Также достаточно просто удалить строку или столбец. Удаляем столбец.\n",
    "\n",
    "```python\n",
    "df.drop(columns=['Temp'], inplace=True)\n",
    "df\n",
    "```\n",
    "А следующая команда удаляет строки.\n",
    "\n",
    "```python\n",
    "df.drop([1, 2], inplace=True)\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень удобно для операций над столбцами использовать сочетание функций apply и lambda.\n",
    "\n",
    "Лябмда-выражения — это особый синтаксис в Python, необходимый для создания анонимных функций. Давайте назовем синтаксис лямбда как лямбда-выражение, а получаемую функцию — лямбда-функцию.\n",
    "\n",
    "Лямбда-выражения в Python позволяют функции быть созданной и переданной (зачастую другой функции) в одной строчке кода.\n",
    "\n",
    "Например, простая функция так:\n",
    "\n",
    "```python\n",
    "#объявим функцию\n",
    "def d100(x,y):\n",
    "    return x/y\n",
    "\n",
    "#вызовем функцию\n",
    "d100(1000,10)\n",
    "```\n",
    "\n",
    "А можно объявить ее и в одну строчку, причем, часто нет необходимости присваивать ее переменной.\n",
    "\n",
    "```python\n",
    "f= lambda x,y: x/y\n",
    "f(1000,100)\n",
    "```\n",
    "\n",
    "Анонимные функции (labmbda) используют как аргумент нескольких функций - map(), filter(), reduce(), apply().\n",
    "\n",
    "`apply()` работает в Series и в качестве аргумента может принимать функции и применяет ее ко всем элементам списка.\n",
    "\n",
    "```python\n",
    "df['Revenue']=df['Revenue'].apply(lambda x: x*1000)\n",
    "df.head()\n",
    "```\n",
    "\n",
    "Apply() можно вызывать и к строке, обращаясь затем к элементам строки по номеру или названии. Для этого надо указать параметр axis=1.\n",
    "\n",
    "Ниже мы перемножаем два столбца между собой. \n",
    "\n",
    "```python\n",
    "df['Labor']=df.apply(lambda x:x['Revenue']/x['Personal'], axis=1)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame позволяет легко делать группировки.\n",
    "Загрузим таблицу ots_p.\n",
    "\n",
    "```python\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "                \"mysql+pymysql://root:__PASS__@__IP___/rzd\", encoding='utf8', convert_unicode=True\n",
    "            )\n",
    "\n",
    "with engine.connect() as session:\n",
    "    df=pd.read_sql('SELECT * FROM ots_p LIMIT 1000', con=session)\n",
    "```\n",
    "\n",
    "Выполним агрегацию по столбцу \"Категория\" и посчитаем количество случаев по каждой категории.\n",
    "\n",
    "```python\n",
    "df.groupby([\"Категория\"])['Категория'].count()\n",
    "```\n",
    "\n",
    "К результатам можно применять слудующие функции:\n",
    "- `count`\tКоличество строк\n",
    "- `sum`\tСумма\n",
    "- `mean`\tСреднее значение\n",
    "- `mad`\tСредняя абсолютное отклонение\n",
    "- `median`\tМедиана\n",
    "- `min`\tМинимум\n",
    "- `max`\tМаксимум\n",
    "- `mode`\tМода\n",
    "- `abs`\tАбсолютное значение\n",
    "- `std`\tСтандартное отклонение\n",
    "- `var`\tВариация\n",
    "\n",
    "Также можно получить результат сразу по нескольким столбцам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеет библиотека и аналог сводных таблиц в Excel. Общий синтаксис метода:\n",
    "\n",
    "```python\n",
    "pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean')\n",
    "```\n",
    "\n",
    "Простой вариант применения сводных таблиц. Посчитаем среднюю продолжительность в разрезе типа и категории отказа. \n",
    "\n",
    "```python\n",
    "df.pivot_table(index=['Тип'], columns=['Категория'], values='Длительность', aggfunc='mean')\n",
    "```\n",
    "\n",
    "Более сложный вариант, когда мы применяем разные функции к агрегируемым данным.\n",
    "\n",
    "```python\n",
    "df.pivot_table(values=['Категория', 'Тип', 'Длительность', 'От', 'Кому'], index='Тех.средство',\n",
    "                        aggfunc={ 'Категория': np.median, 'Тип':'first', 'Длительность':np.mean, 'От': 'last', \n",
    "                                 'Кому':'last'})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Прочитайте 1000 строк таблицы `grdp`. \n",
    "\n",
    "На ее примере:\n",
    "- Умножьте на 10 столбец \"Продолжительность\" с использованием функции `apply()`\n",
    "- Удалите столбец \"index\"\n",
    "- Добавьте столбец с названием\"Временный\", заполните его значением 1\n",
    "- Выполните группировку по столбцу \"Деффект\" и посчитайте среднее по столбцу \"Продолжительность\"\n",
    "- Постройте сводную таблицу с индексом \"Деффект\" и агрегируйте поля \"Телеграмма\", \"Продолжительность\", \"Грз\", \"Характер\" используя функции на Ваше усмотрение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кодирование категориальных переменных\n",
    "\n",
    "Категориальные признаки называют по-разному: факторными, номинальными. Их значения определяют факт принадлежности к какой-то категории. Примеры таких признаков: пол, страна проживания, номер группы, категория товаров и т.п. Ясно, что для компьютерной обработки вместо «понятного для человека» значения (в случае страны — ‘Russia’, ‘GB’, ‘France’ и т.п.) хранят числа. \n",
    "\n",
    "Создадим для примера небольшой DataFrame.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Имя':['Иван', 'Петр', 'Мария', 'Ирина'],\n",
    "                    'Пол':['М','М', 'Ж', 'Ж'], \n",
    "                    'Волосы':['Шатен', 'Блонд', 'Рыжий', 'Блонд'],\n",
    "                    'Английский':['Хорошо', 'Хорошо', 'Отлично', 'Не владеет'],\n",
    "                    'Возраст':[12, 25, 27, 33]})\n",
    "\n",
    "# удобный код, который делит на количественные и категориальные переменные\n",
    "categorical_columns = [c for c in df.columns if df[c].dtype.name == 'object']\n",
    "numerical_columns   = [c for c in df.columns if df[c].dtype.name != 'object']\n",
    "print(\"Категориальные:\", categorical_columns, \"Числовые\",numerical_columns)\n",
    "\n",
    "df\n",
    "```\n",
    "\n",
    "Посмотреть количество переменных можно с помощьюме метода `.unique()`\n",
    "\n",
    "```python\n",
    "print(df['Пол'].unique()) #['М' 'Ж']\n",
    "\n",
    "print(df['Волосы'].unique()) #['Шатен' 'Блонд' 'Рыжий']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Способ кодирования зависит от количества уникальных значений. Если их всего два, то используем значения 0 и 1. Если больше, нужны более сложные походы.\n",
    "\n",
    "Чтобы закодировать столбец с двумя значениями подойдет метода pandas\n",
    "```python\n",
    "pd.get_dummies(df['Пол'], drop_first=True)\n",
    "```\n",
    "\n",
    "Таким же образом можем закодировать и столбец \"Волосы\". Фактически сразу добавим новые столбцы к нашей таблице.\n",
    "\n",
    "```python\n",
    "pd.get_dummies(df, columns=['Волосы'])\n",
    "```\n",
    "\n",
    "Как правило, чтолбцов делают меньше чем переменных в столбце на единицу.\n",
    "\n",
    "Если цвет мы должны кодировать именно фиктивными переменными, то знание языка мы можем закодировать порядковыми номерами. Поясню: если цвет волос \"Шатен\" закодирован номером 0, \"Блонд\" - 2, \"Рыжий\" - 3, то это ошибка, так как это разные цвета. Между \"Блонд\" и \"Шатен\" расстояние не больше, чем между \"Блонд\" и \"Рыжий\". А вот между знанием хорошо и отлично английского языка действительно может быть меньше, чем полное незнание языка и отличное им владение.\n",
    "\n",
    "Можно использовать метод factorize: он автоматически сформирует список, который можно использовать как значения столбца.\n",
    "\n",
    "```python\n",
    "print(pd.factorize(df['Английский'])[0])\n",
    "print(pd.factorize(df['Английский'])[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описанный выше подход хорош если нам не надо делить выборку на тестовую и обучающую. В противном случае, мы фактически получаем \"утечку\" информации из тестового набора. А также возникают сложности с кодированием новых данных. В этом случае применим методы из библиотеки `sklearn `. Посомтрим вначале на более простой вариант, кодирование через метки.\n",
    "\n",
    "[Документация](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder() #создаем объект\n",
    "#тренируем и сразу преобразовываем. Могут быть и последовательные операции\n",
    "label_encoded_data = label_encoder.fit_transform(df['Английский']) \n",
    "\n",
    "print(label_encoded_data) #[2 2 1 0]\n",
    "# закодируем новые данные\n",
    "print(label_encoder.transform(['Хорошо', 'Отлично'])) #[2 1]\n",
    "#обратное преобразование\n",
    "print(label_encoder.inverse_transform(label_encoded_data)) #['Хорошо' 'Хорошо' 'Отлично' 'Не владеет']\n",
    "```\n",
    "\n",
    "Аналогичным образом выполним dummy кодирование. Единственное, что мы можем кодировать сразу несколько столбцов.\n",
    "\n",
    "[Документация](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "```python\n",
    "onehotencoder = OneHotEncoder() #объект класса\n",
    "# преобразуем\n",
    "x = onehotencoder.fit_transform(df[['Английский', \"Волосы\"]]).toarray()\n",
    "print(x) \n",
    "# выполним преобразование новых данных\n",
    "print(onehotencoder.transform([['Хорошо', 'Шатен']]).toarray()) #[[0. 0. 1. 0. 0. 1.]]\n",
    "#получим уникальные значения категорий\n",
    "print(onehotencoder.categories_)\n",
    "# выполним обратное преобразование\n",
    "print(onehotencoder.inverse_transform([[0, 0, 1, 0, 0, 1]]))\n",
    "#получим названия столбцов\n",
    "print(onehotencoder.get_feature_names(['Английский','Волосы']))\n",
    "```\n",
    "\n",
    "При создании объекта класса можно передать следующие параметры:\n",
    "- `handle_unknown='ignore'` - игнорировать при преобразовании неизвестные значения\n",
    "- `drop='first'` - удалить первый\n",
    "\n",
    "Полный код преобразования для нашего примера может выглядеть следующим образом.\n",
    "```python\n",
    "onehotencoder = OneHotEncoder(drop='first')\n",
    "x = onehotencoder.fit_transform(df[[\"Пол\", \"Английский\", \"Волосы\"]]).toarray()\n",
    "col=onehotencoder.get_feature_names([\"Пол\", \"Английский\", \"Волосы\"])\n",
    "df_data=pd.DataFrame(x, columns=col) #создадим новый DataFrame\n",
    "df_data['Возраст']=df['Возраст'] #добавим столбец с возрастом из оригинальной таблицы\n",
    "df_data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Умные способы кодирования\n",
    "\n",
    "Когда не хотят заполонять признаковую матрицу кучей бинарных признаков, применяют кодировки, в которых категории кодируются какими-то интерпретируемыми значениями. Например, если это категория товаров в интернет-магазине, то логично её закодировать средней ценой товара. Тогда, по крайней мере, наш новый признак упорядочивает категории по дороговизне. В любом случае, делается это с помощью функции map и groupby. Кстати, даже если бы функции map не было, можно было бы обойтись выражением `data[feature].apply(lambda x: dct[x])`\n",
    "\n",
    "Самый примитивный способ кодирования — заменить каждую категорию числом входящих в неё объектов (т.е. знания других признаков вообще не нужно). Это делается в одну строчку кода: `data[newfeature] = data[feature].map(data.groupby(feature).size())`.\n",
    "\n",
    "## Биннинг\n",
    "\n",
    "Биннинг или объединение данных - это метод предварительной обработки данных, используемый для уменьшения влияния незначительных ошибок наблюдения. Исходные значения данных, попадающие в заданный небольшой интервал (бин), заменяются значением, представляющим этот интервал, часто центральным значением. Это форма квантования.\n",
    "\n",
    "Ниже простая техника для разделения на группы.\n",
    "\n",
    "```python\n",
    "bins = [0, 10, 20, 30, 40] #границы классов\n",
    "labels = [1,2,3, 4] # меток на одну меньше, чем границ корзин\n",
    "#добавим столбец\n",
    "df['binned'] = pd.cut(df['Возраст'], bins=bins, labels=labels) \n",
    "print (df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Загрузите 1000 строк таблицы `grdp`, закодировать OneHotEncoder столбцы:\n",
    "- Регион\n",
    "- Тип виновного предприятия\n",
    "- Вид работ.\n",
    "\n",
    "Закодировать LabelEncoder столбец \"статус события\".\n",
    "\n",
    "Создать новый DataFrame с данными и добавить столбец \"Итоговый суммарный ущерб (тыс.руб.)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка и подготовка данных\n",
    "\n",
    "Одна из самых трудоемких задачи при анализе, это первичная подготовка данных. Где нам надо решить целый комплекс задач:\n",
    "- проблема пропусков\n",
    "- оценить значимость информации\n",
    "- выполнить кодирование\n",
    "- провести первичный разведовательный анализ данных.\n",
    "\n",
    "В этой задаче будем работать с набором данных ku_asrb.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "                \"mysql+pymysql://root:__PASSS__@__IP___/rzd\", encoding='utf8', convert_unicode=True\n",
    "            )\n",
    "\n",
    "with engine.connect() as session:\n",
    "    df=pd.read_sql('SELECT * FROM ku_asrb LIMIT 1000', con=session)\n",
    "    \n",
    "df.sample(4)\n",
    "```\n",
    "\n",
    "Команды `df.info()` позволит получить первчиную информацию о датасете: `1000 non-null int64`. Первое число это количество не нулевых значений (non-null), а int64 тип значения поля.\n",
    "\n",
    "Для учебного примера будем использовать только часть данных (столбцов).\n",
    "\n",
    "```python\n",
    "col=['Уникальный идентификатор события (внутри дороги)',\n",
    "       'Код дороги', 'Статус события', 'Дата события',\n",
    "       'Дата создания события в системе AC PБ', 'Тип виновного предприятия',\n",
    "       'Функциональный филиал', 'Региональный центр',\n",
    "       'Количество задержанных поездов',\n",
    "       'Размер возмещенного ущерба (тыс.руб.)',\n",
    "       'Итоговый суммарный ущерб (тыс.руб.)']\n",
    "df=df[col]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим количество пропусков по столбцам. На это удобно взглянуть как при помощи диаграммы, так и вывести статистику. Сам код мы изучим подробно чуть позже. Пока важнее результат.\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('ggplot')\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,8)\n",
    "sns.heatmap(df.isnull())\n",
    "```\n",
    "\n",
    "И посчитаем процент пропусков.\n",
    "\n",
    "```python\n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что делать с пропущенными значениями?\n",
    "\n",
    "Не существует общих решений для проблемы отсутствующих данных. Для каждого конкретного набора приходится искать наиболее подходящие методы или их комбинации.\n",
    "\n",
    "Разберем четыре самых распространенных техники. Они помогут в простых ситуациях, но, скорее всего, придется проявить творческий подход и поискать нетривиальные решения, например, промоделировать пропуски.\n",
    "\n",
    "#### Отбрасывание записей\n",
    "\n",
    "Первая техника в статистике называется методом удаления по списку и заключается в простом отбрасывании записи, содержащей пропущенные значения. Это решение подходит только в том случае, если недостающие данные не являются информативными.\n",
    "\n",
    "```python\n",
    "df.dropna(axis='index', how='any') #чтобы применить изменения, добавить в скобки inplace=True\n",
    "```\n",
    "\n",
    "Также можно использовать параметр `how='all'` - будет удалять только пустые строки. А также `thresh=int` - требуется не менее какого-то количества не нулевых значений. `subset` принимает список столбцов, которые надо включить в анализ.\n",
    "\n",
    "#### Отбрасывание признаков\n",
    "\n",
    "Как и предыдущая техника, отбрасывание признаков может применяться только для неинформативных признаков.\n",
    "\n",
    "```python\n",
    "df.dropna(axis='columns', how='any')\n",
    "```\n",
    "\n",
    "#### Внесение недостающих значений\n",
    "\n",
    "Для численных признаков можно воспользоваться методом принудительного заполнения пропусков. Например, на место пропуска можно записать среднее или медианное значение, полученное из остальных записей.\n",
    "\n",
    "Для категориальных признаков можно использовать в качестве заполнителя наиболее часто встречающееся значение.\n",
    "\n",
    "Изучим частоту встречаемости значений.\n",
    "\n",
    "```python\n",
    "df['Функциональный филиал'].value_counts()\n",
    "```\n",
    "\n",
    "Проведем замену.\n",
    "\n",
    "```python\n",
    "df['Функциональный филиал'].fillna('ЦДИ ОАО \"РЖД\"', inplace=True)\n",
    "```\n",
    "\n",
    "#### Замена недостающих значений\n",
    "\n",
    "Можно использовать некоторый дефолтный плейсхолдер для пропусков, например, новую категорию _MISSING_ для категориальных признаков или число -999 для числовых.\n",
    "\n",
    "Таким образом, мы сохраняем данные о пропущенных значениях, что тоже может быть ценной информацией.\n",
    "\n",
    "```python\n",
    "df['Региональный центр'].fillna('_MISSING_', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование типов\n",
    "\n",
    "Изучая образцы данных, мы видим, что числа обозначены как нечисловые значения. В этих случаях важно выполнить приведение типов. Но рекомендуется это делать только после заполнения пропусков.\n",
    "\n",
    "Проще всего выполнить преобразование с использованием метода `.astype()`\n",
    "\n",
    "```python\n",
    "df['Итоговый суммарный ущерб (тыс.руб.)']=df['Итоговый суммарный ущерб (тыс.руб.)'].astype(float)\n",
    "```\n",
    "\n",
    "Но он выдаст исключение, так как не сможет преобразавать некоторые значения. Можно было бы использовать параметр `errors=‘ignore’`, но проблемы бы появились позже. Исследуем ситуацию.\n",
    "\n",
    "```python\n",
    "for i in df['Итоговый суммарный ущерб (тыс.руб.)'].array:\n",
    "    try:\n",
    "        z=float(i)\n",
    "    except:\n",
    "        print(i)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что часть значений ошибочны. Нам надо их заменить на нули (или удалить), фактически это пропуски. А затем выполнить преобразование типа.\n",
    "\n",
    "```python\n",
    "df.loc[df['Итоговый суммарный ущерб (тыс.руб.)']=='.', 'Итоговый суммарный ущерб (тыс.руб.)']='0'\n",
    "df['Итоговый суммарный ущерб (тыс.руб.)']=df['Итоговый суммарный ущерб (тыс.руб.)'].astype(float)\n",
    "```\n",
    "\n",
    "Тоже самое проделаем со столбцом \"Размер возмещенного ущерба (тыс.руб.)\".\n",
    "\n",
    "Со столбцом \"Количество задержанных поездов\" несколько сложнее. Мы видим, что время можно преобразовать в секунды для удобства наализа. Или в другой формат времени. \n",
    "\n",
    "Напишем небольшую вспомогательную функцию.\n",
    "\n",
    "```python\n",
    "def time_to_sec(s):\n",
    "    s3=s.split(':')\n",
    "    if len(s3)<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(s3[0])*60*60+int(s3[1])*60+int(s3[2])\n",
    "    \n",
    "df['Количество задержанных поездов']=df['Количество задержанных поездов'].apply(lambda x: time_to_sec(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть еще два столбца с датами \"Дата события\" и \"Дата создания события в системе AC PБ\". Здесь нам придется \"разобрать\" строку в дату по шаблону.\n",
    "\n",
    "```python\n",
    "df['Дата события']=df['Дата события'].apply(lambda x: pd.to_datetime(x, format='%d%b%Y:%H:%M:%S'))\n",
    "```\n",
    "\n",
    "Получим ошибку, так как не все строки введены корректно. Придется также написать небольшую функцию.\n",
    "\n",
    "```python\n",
    "def ddate(s):\n",
    "    try:\n",
    "        res=pd.to_datetime(s, format='%d%b%Y:%H:%M:%S')\n",
    "    except:\n",
    "        res=np.NaN\n",
    "    return res\n",
    "df['Дата события']=df['Дата события'].apply(lambda x: ddate(x))\n",
    "```\n",
    "\n",
    "[Инструкция по формату](https://www.programiz.com/python-programming/datetime/strptime)\n",
    "\n",
    "Посмотрим, в каких строках не смогло прозойти преобразование.\n",
    "\n",
    "```python\n",
    "df[df['Дата события'].isna()]\n",
    "```\n",
    "\n",
    "Удалим эти строки и проделаем операцию преобразования со столбцом \"Дата создания события в системе AC PБ\"\n",
    "\n",
    "```python\n",
    "df.drop(df[df['Дата события'].isna()].index, axis='index', inplace=True)\n",
    "df['Дата создания события в системе AC PБ']=df['Дата создания события в системе AC PБ'].apply(lambda x: ddate(x))\n",
    "df[df['Дата события'].isna()]\n",
    "```\n",
    "\n",
    "А также можем создать новый признак, это количество времени в секундах между временем события и его регистрацией.\n",
    "\n",
    "```python\n",
    "df['Время до регистрации']=df.apply(lambda x:(x['Дата создания события в системе AC PБ']-x['Дата события']).total_seconds(), axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Загрузите 1000 строк таблицы ku_asutnbd. Проведите преобразование и очистку данных по столбцам `'Дата нарушения', 'Дата расшифровки', 'Скорость фактич', 'Начальный км', 'Путь', 'Вес'`.\n",
    "\n",
    "А именно, отработайте по пропущенным значениям:\n",
    "- удаление\n",
    "- замену\n",
    "\n",
    "Преобразуйе в даты и числовой формат столбцы. Учтите, что сменился шаблон даты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация данных\n",
    "\n",
    "Для того, чтобы эффективно проводить разведочный анализ, нам надо познакомитсья со способами визуализации данных в Python.\n",
    "\n",
    "Самая популярная библиотека визуализации данных, интегрированная в том числе в библиотеку pandas - это `matplotlib`.\n",
    "\n",
    "Matplotlib cостоит из множества модулей. Модули наполнены различными классами и функциями, которые иерархически связаны между собой.\n",
    "\n",
    "### Иерархическая структура рисунка в matplotlib\n",
    "\n",
    "Главной единицей (объектом самого высокого уровня) при работе с matplotlib является рисунок (Figure). Любой рисунок в matplotlib имеет вложенную структуру и чем-то напоминает матрёшку. Пользовательская работа подразумевает операции с разными уровнями этой матрёшки:\n",
    "\n",
    "Figure(Рисунок) -> Axes(Область рисования) -> Axis(Координатная ось)\n",
    "\n",
    "#### Рисунок (Figure)\n",
    "\n",
    "Рисунок является объектом самого верхнего уровня, на котором располагаются одна или несколько областей рисования (Axes), элементы рисунка Artisits (заголовки, легенда и т.д.) и основа-холст (Canvas). На рисунке может быть несколько областей рисования Axes, но данная область рисования Axes может принадлежать только одному рисунку Figure.\n",
    "\n",
    "#### Область рисования (Axes)\n",
    "\n",
    "Область рисования является объектом среднего уровня, который является, наверное, главным объектом работы с графикой matplotlib в объектно-ориентированом стиле. Это то, что ассоциируется со словом \"plot\", это часть изображения с пространством данных. Каждая область рисования Axes содержит две (или три в случае трёхмерных данных) координатных оси (Axis объектов), которые упорядочивают отображение данных.\n",
    "\n",
    "#### Координатная ось (Axis)\n",
    "\n",
    "Координатная ось являются объектом среднего уровня, которые определяют область изменения данных, на них наносятся деления ticks и подписи к делениям ticklabels. Расположение делений определяется объектом Locator, а подписи делений обрабатывает объект Formatter. Конфигурация координатных осей заключается в комбинировании различных свойств объектов Locator и Formatter.\n",
    "\n",
    "#### Элементы рисунка (Artists)\n",
    "\n",
    "Элементы рисунка Artists являются как бы красной линией для всех иерархических уровней. Практически всё, что отображается на рисунке является элементом рисунка (Artist), даже объекты Figure, Axes и Axis. Элементы рисунка Artists включают в себя такие простые объекты как текст (Text), плоская линия (Line2D), фигура (Patch) и другие.\n",
    "\n",
    "Когда происходит отображение рисунка (figure rendering), все элементы рисунка Artists наносятся на основу-холст (Canvas). Большая часть из них связывается с областью рисования Axes. Также элемент рисунка не может совместно использоваться несколькими областями Axes или быть перемещён с одной на другую.\n",
    "\n",
    "\n",
    "```python\n",
    "# де-факто стандарт вызова pyplot в python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()   # Создание объекта Figure\n",
    "print (fig.axes)   # Список текущих областей рисования пуст\n",
    "print (type(fig))   # тип объекта Figure\n",
    "plt.scatter(1.0, 1.0)   # scatter - метод для нанесения маркера в точке (1.0, 1.0)\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Элементы рисунка Artists\n",
    "\n",
    "Всё пространство рисунка Figure (прямоугольной или иной формы) можно использовать для нанесения других элементов рисунка, например, контейнеров Axes, графических примитивов в виде линий, фигур, текста и так далее. В любом случае каждый рисунок можно структурно представить следующим образом:\n",
    "\n",
    "- Область рисования Axes\n",
    "  - Заголовок области рисования -> plt.title();\n",
    "- Ось абсцисс Xaxis\n",
    "  - Подпись оси абсцисс OX -> plt.xlabel();\n",
    "- Ось абсцисс Yaxis\n",
    "  - Подпись оси абсцисс OY -> plt.ylabel();\n",
    "- Легенда -> plt.legend()\n",
    "- Цветовая шкала -> plt.colorbar()\n",
    "  - Подпись горизонтальной оси абсцисс OY -> cbar.ax.set_xlabel();\n",
    "  - Подпись вертикальной оси абсцисс OY -> cbar.ax.set_ylabel();\n",
    "- Деления на оси абсцисс OX -> plt.xticks()\n",
    "- Деления на оси ординат OY -> plt.yticks()\n",
    "\n",
    "Для каждого из перечисленных уровней-контейнеров есть возможность нанести заголовок (title) или подпись (label). Подписи к рисунку облегчают понимание того, в каких единицах представлены данные на графике или диаграмме.\n",
    "\n",
    "Также часто на рисунок наносятся линии вспомогательной сетки (grid). В pyplot она вызывается командой plt.grid(). Вспомогательная сетка связана с делениями координатных осей (ticks), которые определяются автоматически исходя из значений выборки. В дальнейшем будет показано как определять положение и задавать значения делений на координатных осях. Стоит сказать, что в matplotlib существуют главные деления (major ticks) и вспомогательные (minor ticks) для каждой координатной оси. По умолчанию рисуются только главные делений и связанные с ними линии сетки grid. В плане настройки главные деления ничем не отличаются от вспомогательных.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lag = 0.1\n",
    "x = np.arange(0.0, 2*np.pi+lag, lag)\n",
    "y = np.cos(x)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.text(np.pi-0.5, 0,  '1 Axes', fontsize=26, bbox=dict( color='w'))\n",
    "plt.text(0.1, 0, '3 Yaxis', fontsize=18, bbox=dict(color='w'), rotation=90)\n",
    "plt.text(5, -0.9, '2 Xaxis', fontsize=18, bbox=dict(color='w'))\n",
    "\n",
    "plt.title('1a TITLE')\n",
    "plt.ylabel('3a Ylabel')\n",
    "plt.xlabel('2a Xlabel ')\n",
    "\n",
    "plt.text(5, 0.85, '6 Xticks', fontsize=12, bbox=dict( color='w'), rotation=90)\n",
    "plt.text(0.95, -0.55, '6 Xticks', fontsize=12, bbox=dict( color='w'), rotation=90)\n",
    "\n",
    "plt.text(5.75, -0.5, '7 Yticks', fontsize=12, bbox=dict( color='w'))\n",
    "plt.text(0.15, 0.475, '7 Yticks', fontsize=12, bbox=dict(color='w'))\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Параметры, которые определяют эти свойства в различных графических командах, обычно имеют одинаковый синтаксис, то есть называются одинаково. Стандартным способом задания свойств какого либо создаваемого объекта (или методу) является передача по ключу: ключ=значение. Наиболее часто встречаемые названия параметров изменения свойств графических объектов перечислены ниже:\n",
    "- color/colors/c - цвет;\n",
    "- linewidth/linewidths - толщина линии;\n",
    "- linestyle - тип линии;\n",
    "- alpha - степень прозрачности (от полностью прозрачного 0 до непрозрачного 1);\n",
    "- fontsize - размер шрифта;\n",
    "- marker - тип маркера;\n",
    "- s - размер маркера в методе plt.scatter(только цифры);\n",
    "- rotation - поворот строки на X градусов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Графические команды\n",
    "\n",
    "В Matplotlib заложены как простые графические команды, так и достаточно сложные. Доступ к ним через pyplot означает использование синтаксиса вида \"plt.название_команды()\".\n",
    "\n",
    "Наиболее распространённые команды для создания научной графики в matplotlib это:\n",
    "\n",
    "- Самые простые графические команды:\n",
    "  - plt.scatter() - маркер или точечное рисование;\n",
    "  - plt.plot() - ломаная линия;\n",
    "  - plt.text() - нанесение текста;\n",
    "- Диаграммы:\n",
    "  - plt.bar(), plt.barh(), plt.barbs(), broken_barh() - столбчатая диаграмма;\n",
    "  - plt.hist(), plt.hist2d(), plt.hlines - гистограмма;\n",
    "  - plt.pie() - круговая диаграмма;\n",
    "  - plt.boxplot() - \"ящик с усами\" (boxwhisker);\n",
    "  - plt.errorbar() - оценка погрешности, \"усы\".\n",
    "- Изображения в изолиниях:\n",
    "  - plt.contour() - изолинии;\n",
    "  - plt.contourf() - изолинии с послойной окраской;\n",
    "- Отображения:\n",
    "  - plt.pcolor(), plt.pcolormesh() - псевдоцветное изображение матрицы (2D массива);\n",
    "  - plt.imshow() - вставка графики (пиксели + сглаживание);\n",
    "  - plt.matshow() - отображение данных в виде квадратов.\n",
    "- Заливка:\n",
    "  - plt.fill() - заливка многоугольника;\n",
    "  - plt.fill_between(), plt.fill_betweenx() - заливка между двумя линиями;\n",
    "- Векторные диаграммы:\n",
    "  - plt.streamplot() - линии тока;\n",
    "  - plt.quiver() - векторное поле.\n",
    "\n",
    "Несколько примеров. Точечная диаграмма.\n",
    "\n",
    "```python\n",
    "import random\n",
    "import numpy as np\n",
    "x=[random.randint(0,100) for i in range(50)]\n",
    "y=[random.randint(100,300) for i in range(50)]\n",
    "\n",
    "fig = plt.figure()\n",
    "# Добавление на рисунок прямоугольной (по умолчанию) области рисования\n",
    "plt.xlabel('Ось X')\n",
    "plt.ylabel('Ось Y')\n",
    "scatter = plt.scatter(x, y)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Столбчатая диаграмма.\n",
    "\n",
    "```python\n",
    "fig = plt.figure()\n",
    "# Добавление на рисунок прямоугольной (по умолчанию) области рисования\n",
    "scatter = plt.bar(x, y)\n",
    "plt.show()\n",
    "```\n",
    " \n",
    "Ящик с усиками.\n",
    "```python\n",
    "fig = plt.figure()\n",
    "scatter = plt.boxplot(x)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Более подробно в практике применения. [Документация](https://pythonworld.ru/novosti-mira-python/scientific-graphics-in-python.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "\n",
    "Seaborn — это более высокоуровневое API на базе библиотеки matplotlib. Seaborn содержит более адекватные дефолтные настройки оформления графиков. Если просто добавить в код import seaborn, то картинки станут гораздо симпатичнее. Также в библиотеке есть достаточно сложные типы визуализации, которые в matplotlib потребовали бы большого количество кода.\n",
    "\n",
    "Для визуализации распределения метрических переменных используются следующие типы графиков:\n",
    "\n",
    "- distplot\n",
    "- jointplot\n",
    "- rugplot\n",
    "- kdeplot\n",
    "\n",
    "### distplot\n",
    "\n",
    "distplot одновременно показывает гистограмму и график плотности распределения.\n",
    "\n",
    "Загрузим вначале библиотеки и набо данных для иллюстрации. \n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()\n",
    "```\n",
    "\n",
    "```python\n",
    "sns.distplot(tips['total_bill']);\n",
    "```\n",
    "\n",
    "Можно оставить только гистограмму.\n",
    "\n",
    "```python\n",
    "sns.distplot(tips['total_bill'], kde=False, bins=30);\n",
    "```\n",
    "\n",
    "```python\n",
    "sns.displot(data=tips, x=\"total_bill\", col=\"time\", kde=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jointplot\n",
    "\n",
    "Функция jointplot() показывает совместное распределение по двум переменным. Она имеет параметр kind который может принимать следующие значения:\n",
    "\n",
    "- “scatter”\n",
    "- “reg”\n",
    "- “resid”\n",
    "- “kde”\n",
    "- “hex”\n",
    "\n",
    "```python\n",
    "sns.jointplot(x='total_bill', y='tip', data=tips, kind='scatter');\n",
    "```\n",
    "\n",
    "```python\n",
    "sns.jointplot(x='total_bill',y='tip',data=tips,kind='hex');\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairplot\n",
    "\n",
    "pairplot показывает отношения между всеми парами переменных.\n",
    "\n",
    "```python\n",
    "sns.pairplot(tips);\n",
    "```\n",
    "\n",
    "Или другой вариант.\n",
    "\n",
    "```python\n",
    "sns.pairplot(tips, hue='sex', palette='Set1');\n",
    "```\n",
    "\n",
    "### lmplot\n",
    "\n",
    "```python\n",
    "sns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boxplot и violinplot\n",
    "\n",
    "Эти два графика используются для изучения формы распределения.\n",
    "\n",
    "#### boxplot\n",
    "\n",
    "Другое название boxplot — ящик с усами или диаграмма размаха. Он был разработан Джоном Тьюки в 1970-х годах.\n",
    "\n",
    "Такой вид диаграммы в удобной форме показывает медиану (или, если нужно, среднее), нижний и верхний квартили, минимальное и максимальное значение выборки и выбросы. Несколько таких ящиков можно нарисовать бок о бок, чтобы визуально сравнивать одно распределение с другим; их можно располагать как горизонтально, так и вертикально. Расстояния между различными частями ящика позволяют определить степень разброса (дисперсии) и асимметрии данных и выявить выбросы.\n",
    "\n",
    "```python\n",
    "sns.boxplot(x=\"day\", y=\"total_bill\", data=tips, palette='rainbow');\n",
    "```\n",
    "Несколько другое представление.\n",
    "\n",
    "```python\n",
    "sns.boxplot(data=tips, palette='rainbow', orient='h');\n",
    "```\n",
    "\n",
    "#### violinplot\n",
    "\n",
    "Выполняет ту же функцию, что и boxplot. По сути это два повёрнутые на 90 и -90 градусов графика плотности распределения, слипшиеся друг с другом.\n",
    "\n",
    "```python\n",
    "sns.violinplot(x=\"day\", y=\"total_bill\", data=tips, palette='rainbow');\n",
    "```\n",
    "\n",
    "```python\n",
    "sns.violinplot(x=\"day\", y=\"total_bill\", data=tips, hue='sex', palette='Set1');\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тепловая карта\n",
    "\n",
    "```python\n",
    "sns.heatmap(tips.corr());\n",
    "```\n",
    "\n",
    "Можно сменить цвета.\n",
    "\n",
    "```python\n",
    "sns.heatmap(tips.corr(),cmap='coolwarm',annot=True);\n",
    "```\n",
    "\n",
    "## Встроенные функции pandas\n",
    "\n",
    "Часто проще построить фигуру следующим образом.\n",
    "\n",
    "[Документация](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.bar.html)\n",
    "\n",
    "```python\n",
    "tips[\"total_bill\"].plot()\n",
    "```\n",
    "\n",
    "Или \n",
    "\n",
    "```python\n",
    "tips.hist(column=[\"total_bill\"], figsize=(10,4), bins=10);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
