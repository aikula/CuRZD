{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оглавление\n",
    "\n",
    "* [Построение предсказательных моделей](#1)\n",
    "\n",
    "* [Подготовка данных](#2)\n",
    "\n",
    "\t* [Кодирование ](#2-1)\n",
    "\n",
    "\t* [Нормирование данных](#2-2)\n",
    "\n",
    "* [Отбор признаков ](#3)\n",
    "\n",
    "\t* [Классификатор RandomForestClassifier](#3-1)\n",
    "\n",
    "\t* [Одномерный отбор признаков](#3-2)\n",
    "\n",
    "\t* [Рекурсивное исключение признаков](#3-3)\n",
    "\n",
    "* [DecisionTreeClassifier](#4)\n",
    "\n",
    "* [Метрики качества модели](#5)\n",
    "\n",
    "\t* [Метрики бинарной классификации](#5-1)\n",
    "\n",
    "\t* [Базовые метрики](#5-2)\n",
    "\n",
    "\t* [Кривые точности и полноты ](#5-3)\n",
    "\n",
    "\t* [ROC и AUC](#5-4)\n",
    "\n",
    "\t* [Метрики многоклассовой классификации](#5-5)\n",
    "\n",
    "* [Оптимизация моделей](#6)\n",
    "\n",
    "\t* [Подготовим данные](#6-1)\n",
    "\n",
    "\t* [Для RandomForest](#6-2)\n",
    "\n",
    "\t* [Для SVM](#6-3)\n",
    "\n",
    "\t* [Логистическая регрессия](#6-4)\n",
    "\n",
    "\t* [MLPClassifier](#6-5)\n",
    "\n",
    "* [Больше алгоритмов](#7)\n",
    "\n",
    "\t* [Линейные алгоритмы](#7-1)\n",
    "\n",
    "\t* [Нелинейные алгоритмы](#7-2)\n",
    "\n",
    "\t* [Ансамблевые алгоритмы](#7-3)\n",
    "\n",
    "* [Задача линейной регрессии](#8)\n",
    "\n",
    "\t* [Линейные алгоритмы](#8-1)\n",
    "\n",
    "\t* [Нелинейные алгоритмы](#8-2)\n",
    "\n",
    "\t* [Ансамблевые алгоритмы](#8-3)\n",
    "\n",
    "\n",
    "# Построение предсказательных моделей<a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "Изначально, нам надо подготовить данные. Ниже год подготовки датасета.\n",
    "\n",
    "# Подготовка данных<a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "Ниже приведен код с подготовкой данных.\n",
    "\n",
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import numpy as np\n",
    "\n",
    "engine = sqlalchemy.create_engine(\n",
    "                \"mysql+pymysql://root:%s@159.69.219.206:3307/rzd\" %(sql_pass), encoding='utf8', convert_unicode=True\n",
    "            )\n",
    "\n",
    "with engine.connect() as session:\n",
    "    df=pd.read_sql('SELECT * FROM ku_asrb', con=session)\n",
    "\n",
    "cChange=['Получили тяжкие телесные повреждения: сотрудников ОАО \"РЖД\"',\n",
    "       'Получили тяжкие телесные повреждения: пассажиров',\n",
    "       'Получили тяжкие телесные повреждения: сторонние',\n",
    "       'Получили тяжкие телесные повреждения: прочие']\n",
    "for i in cChange:\n",
    "    df[i].replace('.','0', inplace=True)\n",
    "\n",
    "df.loc[:,['Получили тяжкие телесные повреждения: сотрудников ОАО \"РЖД\"',\n",
    "       'Получили тяжкие телесные повреждения: пассажиров',\n",
    "       'Получили тяжкие телесные повреждения: сторонние',\n",
    "       'Получили тяжкие телесные повреждения: прочие']].fillna(0, inplace=True)\n",
    "for i in cChange:\n",
    "    df[i]=df[i].astype(float)\n",
    "df['Ранено тяжело']=df[cChange].sum(axis=1)\n",
    "\n",
    "#создадим новой столбец как цель для классификации\n",
    "\n",
    "#Создадим новый столбец, который и будем предсказывать\n",
    "df.loc[df['Итоговый суммарный ущерб (тыс.руб.)']=='.', 'Итоговый суммарный ущерб (тыс.руб.)']='0'\n",
    "df['Итоговый суммарный ущерб (тыс.руб.)']=df['Итоговый суммарный ущерб (тыс.руб.)'].astype(float)\n",
    "df['Ущерб']=df['Итоговый суммарный ущерб (тыс.руб.)'].apply(lambda x: 1 if x>20 else 0)\n",
    "\n",
    "##Номер пути\n",
    "df['Номер пути'].replace('.','0', inplace=True)\n",
    "df.loc[df['Номер пути'].isin(['1','2','3','4']), 'Номер пути']=1\n",
    "df.loc[~df['Номер пути'].isin(['1','2','3','4','0']), 'Номер пути']=2\n",
    "df['Номер пути']=df['Номер пути'].astype(int)\n",
    "\n",
    "Y_regr=df['Итоговый суммарный ущерб (тыс.руб.)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['index', 'Уникальный идентификатор события (внутри дороги)',\n",
    "                'Статус события', 'Дата создания события в системе AC PБ',\n",
    "                'Функциональный филиал', 'Региональный центр', \n",
    "                 'Подразделение', 'ДЗО (организация)', 'ДЗО (предприятие)', \n",
    "                 'Сервисная организация', 'Сервисная организация (предприятие)',\n",
    "                'Классификация нарушения 1 уровень (№344)',\n",
    "                'Классификация нарушения 2 уровень (№344)',\n",
    "               'Классификация нарушения 3 уровень (№344)',\n",
    "               'Причина нарушения 1 уровень', 'Причина нарушения 2 уровень',\n",
    "               'Причина нарушения 3 уровень', 'Причина нарушения 4 уровень',\n",
    "                'Погибло сотрудников ОАО \"РЖД\"', 'Погибло пассажиров',\n",
    "               'Погибло сторонних', 'Погибло прочих', 'Получили тяжкие телесные повреждения: сотрудников ОАО \"РЖД\"',\n",
    "               'Получили тяжкие телесные повреждения: пассажиров',\n",
    "               'Получили тяжкие телесные повреждения: сторонние',\n",
    "               'Получили тяжкие телесные повреждения: прочие','Размер возмещенного ущерба (тыс.руб.)',\n",
    "               'Станция/перегон id', 'Переезд',\n",
    "               'Станция/перегон id', 'Путь общего/необщего пользования',\n",
    "               'Пикет', 'Станция/перегон', 'Дорога НБД'], inplace=True)\n",
    "\n",
    "print('Осталось столбцов', len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приведение типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddate(s):\n",
    "    try:\n",
    "        res=pd.to_datetime(s, format='%d%b%Y:%H:%M:%S')\n",
    "    except:\n",
    "        res=np.NaN\n",
    "    return res\n",
    "df['Дата события']=df['Дата события'].apply(lambda x: ddate(x))\n",
    "df['Дата события'].dropna(inplace=True)\n",
    "\n",
    "#создадим еще два признака - номер месяца и день недели\n",
    "df['Месяц события']=df['Дата события'].apply(lambda x: x.month)\n",
    "df['День недели']=df['Дата события'].apply(lambda x: x.isoweekday())\n",
    "df['Время суток']=df['Дата события'].apply(lambda x: 1 if 8<x.hour<20 else 0)\n",
    "\n",
    "#время\n",
    "def time_to_sec(s):\n",
    "    try:\n",
    "        s3=s.split(':')\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    if len(s3)<3:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(s3[0])*60*60+int(s3[1])*60+int(s3[2])\n",
    "\n",
    "df['Время полного перерыва движения']=df['Время полного перерыва движения'].apply(lambda x: time_to_sec(x))\n",
    "df['Время полного перерыва движения']=df['Время полного перерыва движения'].apply(lambda x: 1 if x>0 else 0)\n",
    "df['Количество задержанных поездов']=df['Количество задержанных поездов'].apply(lambda x: time_to_sec(x))\n",
    "\n",
    "#заполним пропуски\n",
    "df['Тип виновного предприятия'].fillna('Неизвестно', inplace=True)\n",
    "df['Сторонняя организация'].fillna('Неизвестно', inplace=True)\n",
    "\n",
    "#переведем в целочисленный тип\n",
    "df['Погибло всего'].replace('.',0, inplace=True)\n",
    "df['Погибло всего']=df['Погибло всего'].astype(int)\n",
    "\n",
    "df['Ранено легко'].replace('.',0, inplace=True)\n",
    "df['Ранено легко']=df['Ранено легко'].astype(int)\n",
    "\n",
    "df['Километр'].replace('.',0, inplace=True)\n",
    "df['Километр']=df['Километр'].astype(int)\n",
    "\n",
    "df['Общее время задержки'].replace('.',0, inplace=True)\n",
    "df['Общее время задержки']=df['Общее время задержки'].astype(int)\n",
    "\n",
    "df['Регион'].fillna('Неизвестен', inplace=True)\n",
    "\n",
    "#проверим на пропуски\n",
    "print(df.isna().sum())\n",
    "\n",
    "#удалим строки с пропусками\n",
    "df.dropna(axis='index', inplace=True)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удалим выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(np.where(df['Итоговый суммарный ущерб (тыс.руб.)']>30000)[0], inplace=True)\n",
    "df=df[df['Общее время задержки']<18]\n",
    "df=df[df['Количество задержанных поездов']<73000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодирование <a class=\"anchor\" id=\"2-1\"></a>\n",
    "\n",
    "Выполним кодирование категориальных переменных. Закодируем их через LabelEncoder. Такой вариант подходит для классификации, но не подходит для задачи регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Количественные столбцы\n",
    "object_columns=df.select_dtypes(include = ['object']).columns\n",
    "\n",
    "int_columns=list(set(df.columns)-set(object_columns))\n",
    "\n",
    "print('Применим LabelEncoder к столбцам:')\n",
    "[print('-',i) for i in object_columns]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(LabelEncoder)\n",
    "\n",
    "#Перекодируем все столбцы\n",
    "data = df[object_columns].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "for i in int_columns:\n",
    "    data[i]=df[i]\n",
    "    \n",
    "#из даты события можно получить еще ряд признаков\n",
    "data.drop(columns=['Дата события'], inplace=True)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормирование данных<a class=\"anchor\" id=\"2-2\"></a>\n",
    "\n",
    "Воспользуемся самым простым подходом к нормированию данных Мин-Макс скалером. Помним, что в переменной data нам всегда доступны оригинальные данные. \n",
    "\n",
    "Также для применения другого скалера надо перезапустить этот код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "Y=data['Ущерб'].values\n",
    "df_X=data.drop(columns=['Ущерб', 'Итоговый суммарный ущерб (тыс.руб.)'])\n",
    "\n",
    "X = preprocessing.MinMaxScaler().fit_transform(df_X)\n",
    "X=pd.DataFrame(X, columns=df_X.columns)\n",
    "\n",
    "del df #удалим ненужные таблицы из памяти\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#разделим набор на тренировочный и тестовый\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отбор признаков <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "Интуитивно и ошибочно мы считаем, что чем больше признаков подадим на вход модели обучения, тем лучше. Увы, часто это не так. Данные могут неправильно взаимодействовать между собой, дублировать, не содержать полезных сигналов, усложнять обучение модели и резко увеличивать ее объем. Прибегнем к нескольким способам оценить полезность признаков нашей модели. \n",
    "\n",
    "**Обратите внимание:** так как для отбора используются алгоритмы классификации, значения целевой переменной приводятся к целым числам. Если дробная часть значений целевой переменной играет существенную роль, то необходимо или умножить все значения на 100, или преобразовать в категорийные переменные.\n",
    "\n",
    "## Классификатор RandomForestClassifier<a class=\"anchor\" id=\"3-1\"></a>\n",
    "\n",
    "В этом классе реализована метаоценка, которая подходит к ряду рандомизированных деревьев решений (также называемых дополнительными деревьями) в различных подвыборках набора данных и использует усреднение для повышения точности прогнозирования и контроля соответствия.\n",
    "\n",
    "Результаты подобных алгоритмов сложно интерпретировать, но они позволяют сделать оценку значимости признаков.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#feature extraction\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X, Y.astype('int'))\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "ar_f=[]\n",
    "for f, idx in enumerate(indices):\n",
    "    ar_f.append([round(importances[idx],4), X.columns[idx]])\n",
    "print(\"Значимость признака:\")\n",
    "ar_f.sort(reverse=True)\n",
    "ar_f\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобнее отобразить результаты в виде графика.\n",
    "\n",
    "```python\n",
    "d_first = len(X.columns)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(\"Значимость признака\")\n",
    "plt.bar(range(d_first), importances[indices[:d_first]], align='center')\n",
    "plt.xticks(range(d_first), np.array(X.columns)[indices[:d_first]], rotation=90)\n",
    "plt.xlim([-1, d_first]);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на метрику точности R2, но надо понимать, что для несбалансированных классов, как у нас, она плохо подходит.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(model.predict(X), Y) #не совсем точная характеристика!!! \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Несколько усовершенствованный подход\n",
    "\n",
    "Более сложный вариант выбора значимых показателей с использованием RandomForestClassifier.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "select = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    threshold=\"median\")\n",
    "\n",
    "select.fit(X, Y)\n",
    "X_train_l1 = select.transform(X)\n",
    "print(\"форма обуч набора X: {}\".format(X.shape))\n",
    "print(\"форма обуч набора X c l1: {}\".format(X_train_l1.shape))\n",
    "\n",
    "mask = select.get_support()\n",
    "#визуализируем булевы значения -- черный – True, белый – False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Индекс примера\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем результаты в виде списка.\n",
    "\n",
    "```python\n",
    "for i in zip(X.columns, mask):\n",
    "    print(i[1],'<-', i[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Одномерный отбор признаков<a class=\"anchor\" id=\"3-2\"></a>\n",
    "\n",
    "Признаки, имеющие наиболее выраженную взаимосвязь с целевой переменной, могут быть отобраны с помощью статистических критериев. Библиотека scikit-learn содержит класс SelectKBest, реализующий одномерный отбор признаков (univariate feature selection). Этот класс можно применять совместно с различными статистическими критериями для отбора заданного количества признаков. В нашем случае мы используем критерий chi2.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#создаем и тренируем модель\n",
    "test = SelectKBest(score_func=chi2, k='all')\n",
    "fit = test.fit(X, Y.astype('int'))\n",
    "\n",
    "ar2=[]\n",
    "for i in range(0, len(X.columns)):\n",
    "    ar2.append([X.columns[i], round(fit.scores_[i],4)])\n",
    "ar2.sort(key=lambda i: i[1], reverse=True)\n",
    "df_om=pd.DataFrame(ar2, columns=['Признак', \"Значимость\"])\n",
    "print('Значимость признаков в порядке убывания:')\n",
    "df_om\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекурсивное исключение признаков<a class=\"anchor\" id=\"3-3\"></a>\n",
    "\n",
    "Метод рекурсивного исключения признаков (recursive feature elimination, RFE) реализует следующий алгоритм: модель обучается на исходном наборе признаков и оценивает их значимость, затем исключается один или несколько наименее значимых признаков, модель обучается на оставшихся признаках и так далее, пока не останется заданное количество лучших признаков. В документации scikit-learn вы можете подробнее прочитать о классе RFE.\n",
    "\n",
    "В примере ниже метод RFE применяется в сочетании с логистической регрессией для отбора 4-х лучших признаков. Для совместного использования с RFE можно выбирать различные модели, важно лишь, чтобы они были достаточно эффективны и совместимы с RFE.\n",
    "\n",
    "Количество отбираемых признаков можно изменить.\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#создаем модель, которую будем обучать\n",
    "model = LogisticRegression(solver='liblinear', multi_class='auto', random_state=42)\n",
    "\n",
    "rfe = RFE(model, 4) #указано количество отбираемых признаков\n",
    "\n",
    "#обучаем модель\n",
    "fit = rfe.fit(X, Y.astype('int'))\n",
    "\n",
    "#выводим результаты\n",
    "ar3=[]\n",
    "for i in range(0,len(X.columns)):\n",
    "    ar3.append([X.columns[i], fit.support_[i], fit.ranking_[i]])\n",
    "ar3.sort(key=lambda i: i[2])\n",
    "df_rfe=pd.DataFrame(ar3, columns=[\"Признак\", \"Важный\", \"Рэнк\"])\n",
    "df_rfe\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier<a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "Начнем с одной из интересных моделей DecisionTreeClassifier. Эта модель позволит лучше понять в том числе и RandomForest.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Правильность на обучающем наборе: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Правильность на тестовом наборе: {:.3f}\".format(tree.score(X_test, y_test)))\n",
    "print('Важность признака')\n",
    "for i in zip(X.columns, tree.feature_importances_):\n",
    "    print(\"{:.3f}\".format(i[1]),'<-',i[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем отобразить дерево принятия решения со всеми его ветвями.\n",
    "\n",
    "```python\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"0\", \"1\"],\n",
    "feature_names=X.columns, impurity=False, filled=True)\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно сохранить в pdf файл.\n",
    "\n",
    "```python\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"Tree.pdf\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или отобразить на экране в виде более аккуратного рисунка.\n",
    "\n",
    "```python\n",
    "from IPython.display import Image\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, feature_names=X.columns,\n",
    "    class_names=['0','1'],\n",
    "    filled=True, rounded=True,\n",
    "    special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики качества модели<a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "Мы говорили, что точность нашей модели несколько неудовлетворительна, а R2 не самая адекватная оценка. \n",
    "\n",
    "Давайте обучим и протестируем RandomForestClassifier.\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#feature extraction\n",
    "model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(model.predict(X_train), y_train))\n",
    "print(r2_score(model.predict(X_test), y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результаты прогноза при помощи confusion_matrix.\n",
    "\n",
    "```python\n",
    "#матрица количества правильно и ошибочно угаданных классов\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, model.predict(X_test)), columns=[0,1], index=[0,1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ее вариант в виде таблицы с процентами. \n",
    "\n",
    "```python\n",
    "#так же матрица в процентах и более изящном виде\n",
    "matrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "#Build the plot\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "#Add labels to the plot\n",
    "class_names = ['0', '1']                 # !!!!!! указать названия классов!\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Предсказанные классы')\n",
    "plt.ylabel('Истинные классы')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбирая метрику, вы всегда должны помнить о конечной цели проекта машинного обучения. На практике мы, как правило, заинтересованы не только в создании точных прогнозов, но и в том, чтобы использовать их в рамках более масштабного процесса принятия решений. Прежде чем выбрать показатель качества машинного обучения, вам стоит подумать о высокоуровневой цели вашего проекта, которую часто называют бизнес-метрикой (business metric). Последствия, обусловленные выбором конкретного алгоритма для того или иного проекта, называются влиянием на бизнес (business impact). Например, высокоуровневой целью является предотвращение дорожно-транспортных происшествий или уменьшение числа случаев госпитализации. Вы должны выбрать такую модель или такие значения\n",
    "параметров, которые оказывают наибольшее положительное влияние на\n",
    "бизнес-метрику. Часто эта задача является трудной, поскольку оценка\n",
    "влияния конкретной модели на бизнес может потребовать ее внедрения\n",
    "в реальное производство.\n",
    "\n",
    "## Метрики бинарной классификации<a class=\"anchor\" id=\"5-1\"></a>\n",
    "\n",
    "Бинарная классификация является, пожалуй, наиболее распространенным и концептуально простым примером практического применения машинного обучения. Однако даже при решении этой простой задачи существует целый ряд нюансов. Прежде чем мы углубимся в альтернативные метрики, давайте рассмотрим ситуации, в которых правильность измерения может ввести в заблуждение. Вспомним, что в случае бинарной классификации мы говорим о положительном (positive) классе и отрицательном (negative) классе, подразумевая под положительным классом интересующий нас класс.\n",
    "\n",
    "Одна из возможных ошибок заключается в том, что здоровый пациент будет классифицирован как больной (положительный класс), что даст повод для дополнительного тестирования. Дополнительное обследование приведет к некоторым затратам и неудобствам для пациента (и, возможно, к определенному психическому дискомфорту). Пример, неправильно спрогнозированный как положительный, называется ложно положительным (false positive). Другая возможная ошибка состоит в том, что больной пациент будет классифицирован как здоровый (отрицательный класс), не пройдет дополнительные тесты и не получит лечения. Недиагностированный вовремя рак может привести к серьезным проблемам со здоровьем и может даже закончиться смертельным исходом. Пример, неправильно спрогнозированный как отрицательный, называется ложно отрицательным (false negative). В статистике ложно положительный пример также известен как ошибка I \n",
    "рода (type I error), а ложно отрицательный пример – как ошибка II рода (type II error). Мы будем придерживаться определений «ложно отрицательный пример» и «ложно положительный пример», поскольку они являются более явными и их легче запомнить. В примере с диагностикой рака очевидно, что мы хотим минимизировать долю ложно отрицательных примеров, тогда как ложно положительные примеры можно считать гораздо менее значительной неприятностью.\n",
    "\n",
    "## Базовые метрики<a class=\"anchor\" id=\"5-2\"></a>\n",
    "\n",
    "![Матрица ошибок](https://miro.medium.com/max/356/1*g5zpskPaxO8uSl0OWT4NTQ.png)\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "Интуитивно понятной, очевидной и почти неиспользуемой метрикой является accuracy — доля правильных ответов алгоритма:\n",
    "\n",
    "Эта метрика бесполезна в задачах с неравными классами, и это легко показать на примере.\n",
    "\n",
    "**Accuracy (все правильные / все) = TP + TN / TP + TN + FP + FN**\n",
    "\n",
    "Допустим, мы хотим оценить работу спам-фильтра почты. У нас есть 100 не-спам писем, 90 из которых наш классификатор определил верно (True Negative = 90, False Positive = 10), и 10 спам-писем, 5 из которых классификатор также определил верно (True Positive = 5, False Negative = 5).\n",
    "\n",
    "Тогда: accuracy=(5+90)/(5+90+10+5)=0.864\n",
    "\n",
    "Однако если мы просто будем предсказывать все письма как не-спам, то получим более высокую accuracy:\n",
    "\n",
    "accuracy=(0+100)/(0+100+0+10)=0.909\n",
    "\n",
    "При этом наша модель совершенно не обладает никакой предсказательной силой, так как изначально мы хотели определять письма со спамом. Преодолеть это нам поможет переход с общей для всех классов метрики к отдельным показателям качества классов.\n",
    "\n",
    "### Precision, recall и F-мера\n",
    "\n",
    "Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики precision (точность) и recall (полнота).\n",
    "\n",
    "**Precision (правильные позитивные / на предсказанные как позитивные) = TP / TP + FP**\n",
    "\n",
    "**Sensitivity aka Recall (правильные позитивные / на все настоящие позитивные) = TP / TP + FN**\n",
    "\n",
    "Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм.\n",
    "\n",
    "Именно введение precision не позволяет нам записывать все объекты в один класс, так как в этом случае мы получаем рост уровня False Positive. Recall демонстрирует способность алгоритма обнаруживать данный класс вообще, а precision — способность отличать этот класс от других классов.\n",
    "\n",
    "Как мы отмечали ранее, ошибки классификации бывают двух видов: False Positive и False Negative. В статистике первый вид ошибок называют ошибкой I-го рода, а второй — ошибкой II-го рода. В нашей задаче, например, по определению оттока абонентов ошибкой первого рода будет принятие лояльного абонента за уходящего, так как наша нулевая гипотеза состоит в том, что никто из абонентов не уходит, а мы эту гипотезу отвергаем. Соответственно, ошибкой второго рода будет являться «пропуск» уходящего абонента и ошибочное принятие нулевой гипотезы.\n",
    "Precision и recall не зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок.\n",
    "Часто в реальной практике стоит задача найти оптимальный (для заказчика) баланс между этими двумя метриками. Классическим примером является задача определения оттока клиентов.\n",
    "\n",
    "Очевидно, что мы не можем находить всех уходящих в отток клиентов и только их. Но, определив стратегию и ресурс для удержания клиентов, мы можем подобрать нужные пороги по precision и recall. Например, можно сосредоточиться на удержании только высокодоходных клиентов или тех, кто уйдет с большей вероятностью, так как мы ограничены в ресурсах колл-центра.\n",
    "Обычно при оптимизации гиперпараметров алгоритма (например, в случае перебора по сетке GridSearchCV) используется одна метрика, улучшение которой мы и ожидаем увидеть на тестовой выборке.\n",
    "\n",
    "Хотя точность и полнота являются очень важными метриками, сами\n",
    "по себе они не дадут вам полной картины. Одним из способов\n",
    "подытожить их является F-мера (F-measure), которая представляет собой\n",
    "гармоническое среднее точности и полноты:\n",
    "\n",
    "**F1=2 x (precision x recall)/(precision + recall)**\n",
    "\n",
    "Поскольку F1-мера учитывает точность и полноту, то для бинарной классификации несбалансированных данных она может быть лучшей метрикой, чем правильность.\n",
    "\n",
    "## Кривые точности и полноты <a class=\"anchor\" id=\"5-3\"></a>\n",
    "\n",
    "Изменение порога, используемого для классификации решений модели – это способ, позволяющий найти компромисс между точностью и полнотой для данного классификатора. Возможно, вы хотите пропустить менее 10% положительных примеров, таким образом, желаемое значение полноты составит 90%. Решение зависит от конкретного примера и оно должно определяться бизнес- целями. Как только поставлена конкретная цель, скажем, задано конкретное значение полноты или точности для класса, можно установить соответствующий порог. Всегда можно задать то или иное пороговое значение для реализации конкретной цели (например, достижения значения полноты 90%). Трудность состоит в разработке такой модели, которая при этом пороге еще и будет иметь приемлемое значение точности, ведь классифицировав все примеры как положительные, вы получите значение полноты, равное 100%, но при этом ваша модель будет бесполезной.\n",
    "\n",
    "Требование, выдвигаемое к качеству модели (например, значение полноты должно быть 90%), часто называют рабочей точкой (operating point). Фиксирование рабочей точки часто бывает полезно в контексте бизнеса, чтобы гарантировать определенный уровень качества клиентам или другим группам лиц внутри организации.\n",
    "\n",
    "Как правило, при разработке новой модели нет четкого представления о том, что будет рабочей точкой. По этой причине, а также для того, чтобы получить более полное представление о решаемой задаче, полезно сразу взглянуть на все возможные пороговые значения или все возможные соотношения точности и полноты для этих пороговых значений. Данную процедуру можно осуществить с помощью инструмента, называемого кривой точности-полноты (precision-recall curve). Функцию для вычисления кривой точности-полноты можно найти в модуле sklearn.metrics. Ей необходимо передать фактические метки классов и спрогнозированные вероятности, вычисленные с помощью decision_function или predict_proba:\n",
    "\n",
    "\n",
    "```python\n",
    "#в RandomForestClassifier есть predict_proba, но нет decision_function\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(\n",
    "y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(precision_rf, recall_rf, label=\"rf\")\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(precision_rf[close_default_rf], recall_rf[close_default_rf], '^', c='k',\n",
    "markersize=10, label=\"порог 0.5 rf\", fillstyle=\"none\", mew=2)\n",
    "plt.xlabel(\"Точность\")\n",
    "plt.ylabel(\"Полнота\")\n",
    "plt.legend(loc=\"best\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим еще одну модель - SVC и оценим ее результаты.\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, svc.decision_function(X_test))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "y_test, svc.decision_function(X_test))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "#находим ближайший к нулю порог\n",
    "#в RandomForestClassifier есть predict_proba, но нет decision_function\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(\n",
    "y_test, model.predict_proba(X_test)[:, 1])\n",
    "plt.plot(precision, recall, label=\"svc\")\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "label=\"порог 0 svc\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.xlabel(\"Точность\")\n",
    "plt.ylabel(\"Полнота\")\n",
    "plt.legend(loc=\"best\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица результатов предсказаний.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, svc.predict(X_test)), columns=[0,1], index=[0,1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты опираясь на график.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "y_test, svc.decision_function(X_test))\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "#находим ближайший к нулю порог\n",
    "#в RandomForestClassifier есть predict_proba, но нет decision_function\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(\n",
    "y_test, model.predict_proba(X_test)[:, 1])\n",
    "plt.plot(precision, recall, label=\"svc\")\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "label=\"порог 0 svc\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "\n",
    "plt.plot(precision_rf, recall_rf, label=\"rf\")\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(precision_rf[close_default_rf], recall_rf[close_default_rf], '^', c='k',\n",
    "markersize=10, label=\"порог 0.5 rf\", fillstyle=\"none\", mew=2)\n",
    "plt.xlabel(\"Точность\")\n",
    "plt.ylabel(\"Полнота\")\n",
    "plt.legend(loc=\"best\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что модель RF работает лучше. Это также очевидно из метрики f1.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"f1-мера random forest: {:.3f}\".format(\n",
    "f1_score(y_test, model.predict(X_test))))\n",
    "print(\"f1-мера svc: {:.3f}\".format(f1_score(y_test, svc.predict(X_test))))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC и AUC<a class=\"anchor\" id=\"5-4\"></a>\n",
    "\n",
    "Еще один инструмент, который обычно используется для анализа поведения классификаторов при различных пороговых значениях – это кривая рабочей характеристики приемника (receiver operating characteristics curve) или кратко ROC-кривая (ROC curve). Как и кривая точности-полноты, ROC-кривая позволяет рассмотреть все пороговые значения для данного классификатора, но вместо точности и полноты она показывает долю ложно положительных примеров (false positive rate, FPR) в сравнении с долей истинно положительных примеров (true positive rate). Вспомним, что доля истинно положительных примеров – это просто еще одно название полноты, тогда как доля ложно положительных примеров – это доля ложно положительных примеров от общего количества отрицательных примеров:\n",
    "\n",
    "FRP=FT/(FP+TN)\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, svc.decision_function(X_test))\n",
    "plt.plot(fpr, tpr, label=\"ROC-кривая\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (полнота)\")\n",
    "#находим пороговое значение, ближайшее к нулю\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10,\n",
    "label=\"порог 0\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с кривой точности-полноты, мы хотим подытожить\n",
    "информацию ROC-кривой с помощью одного числа, площади под кривой\n",
    "(обычно ее просто называют AUC, при этом имейте в виду, что речь идет\n",
    "о ROC-кривой). Мы можем вычислить площадь под ROC-кривой с\n",
    "помощью функции roc_auc_score:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import roc_auc_score\n",
    "rf_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "print(\"AUC для случайного леса: {:.3f}\".format(rf_auc))\n",
    "print(\"AUC для SVC: {:.3f}\".format(svc_auc))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики многоклассовой классификации<a class=\"anchor\" id=\"5-5\"></a>\n",
    "\n",
    "Метрики для классификации более чем двух классов, практически не отличаются.\n",
    "\n",
    "```python\n",
    "#загрузим набор данных\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, random_state=0)\n",
    "\n",
    "lr = SVC(max_iter=1000).fit(X_train, y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, pred)))\n",
    "print(classification_report(y_test, pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизация моделей<a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "Каждая модель имеет большое количество параметров. Не всегда удается вручную подобрать их оптимально. В этом случае нам поможет метод GridSearchCV. Так как это достаточно затратная по времени и ресурсам операция, посмотрим на примере двух моделей.\n",
    "\n",
    "## Подготовим данные<a class=\"anchor\" id=\"6-1\"></a>\n",
    "\n",
    "```python\n",
    "from sklearn import preprocessing\n",
    "\n",
    "Y=data['Ущерб'].values\n",
    "df_X=data.drop(columns=['Ущерб', 'Итоговый суммарный ущерб (тыс.руб.)'])\n",
    "\n",
    "X = preprocessing.MinMaxScaler().fit_transform(df_X)\n",
    "X=pd.DataFrame(X, columns=df_X.columns)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#разделим набор на тренировочный и тестовый\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для RandomForest<a class=\"anchor\" id=\"6-2\"></a>\n",
    "\n",
    "**Высоконагруженная операция**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [6,8],\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1', cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Наилучшие значения параметров: {}\".format(CV_rfc.best_params_))\n",
    "print(\"Наилучшее значение кросс-валидац. правильности: {:.2f}\".format(CV_rfc.best_score_))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для SVM<a class=\"anchor\" id=\"6-3\"></a>\n",
    "\n",
    "**Высоконагруженная операция**\n",
    "\n",
    "```python\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "grid_search = GridSearchCV(SVC(), param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Наилучшие значения параметров: {}\".format(grid_search.best_params_))\n",
    "print(\"Наилучшее значение кросс-валидац. правильности {:.2f}\".format(grid_search.best_score_))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим лучшие модели.\n",
    "\n",
    "```python\n",
    "model = RandomForestClassifier( max_depth=8, max_features='auto', n_estimators=200)\n",
    "model.fit(X_train, y_train)\n",
    "svc = SVC(C=10).fit(X_train, y_train)\n",
    "\n",
    "print(\"f1-мера random forest: {:.3f}\".format(f1_score(y_test, model.predict(X_test))))\n",
    "print(\"f1-мера svc: {:.3f}\".format(f1_score(y_test, svc.predict(X_test))))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия<a class=\"anchor\" id=\"6-4\"></a>\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(C=0.1)\n",
    "res=logistic.fit(X_train, y_train)\n",
    "logistic.score(X_test, y_test)\n",
    "\n",
    "print(f1_score(y_test, logistic.predict(X_test)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преимущество модели - это простая интерпретируемость.\n",
    "\n",
    "```python\n",
    "for i in zip(X_train.columns, logistic.coef_[0]):\n",
    "    print(i[0], '->  {:.3f}'.format(i[1]))\n",
    "    \n",
    "print('Intercept: ->  ', logistic.intercept_[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценить вероятности принадлежности к классу.\n",
    "\n",
    "```python\n",
    "logistic.predict_proba(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier<a class=\"anchor\" id=\"6-5\"></a>\n",
    "\n",
    "Одна из самых простых в реализации нейронных сетей для классификации из Scikit-Learn, которая называется MLPClassifier. MLPClassifier расшифровывается как Multi-Layer Perceptron classifier, который в самом названии указывает на нейронную сеть. В отличие от других алгоритмов классификации, таких как опорные вектора или наивный байесовский классификатор, MLPClassifier полагается на базовую нейронную сеть для выполнения задачи классификации.\n",
    "\n",
    "Однако одно сходство с другими алгоритмами классификации Scikit-Learn заключается в том, что реализация MLPClassifier требует не больше усилий, чем реализация Support Vectors, Naive Bayes или любых других классификаторов из Scikit-Learn.\n",
    "\n",
    "- `hidden_layer_sizes`: этот параметр позволяет нам установить количество слоев и количество узлов, которые мы хотим иметь в классификаторе нейронной сети. Каждый элемент в кортеже представляет количество узлов в i-й позиции, где i - это индекс кортежа. Таким образом, длина кортежа обозначает общее количество скрытых слоев в сети.\n",
    "- `max_iter`: обозначает количество эпох.\n",
    "- `activation`: функция активации скрытых слоев.\n",
    "- `solver`: этот параметр определяет алгоритм оптимизации веса для узлов.\n",
    "- `random_state`: параметр позволяет установить начальное число для воспроизведения тех же результатов.\n",
    "\n",
    "```python\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0, max_iter=1000, \n",
    "                    hidden_layer_sizes=[20,10, 20], \n",
    "                    activation = 'relu', early_stopping=True).fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, mlp.predict(X_test)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Больше алгоритмов<a class=\"anchor\" id=\"7\"></a>\n",
    "\n",
    "## Линейные алгоритмы<a class=\"anchor\" id=\"7-1\"></a>\n",
    "- Логистическая регрессия / Logistic Regression (‘LR’). Слово «регрессия» может сбить с толку. Но не забываем, что «Логистическая регрессия» — это алгоритм классификации\n",
    "- Линейный дискриминантный анализ / Linear Discriminant Analysis (‘LDA’)\n",
    "\n",
    "## Нелинейные алгоритмы<a class=\"anchor\" id=\"7-2\"></a>\n",
    "- Метод k-ближайших соседей (классификация) / K-Neighbors Classifier (‘KNN’)\n",
    "- Деревья принятия решений / Decision Tree Classifier (‘CART’)\n",
    "- Наивный классификатор Байеса / Naive Bayes Classifier (‘NB’)\n",
    "- Линейный метод опорных векторов (классификация) / Linear Support Vector Classification (‘LSVC’)\n",
    "- Метод опорных векторов (классификация) / C-Support Vector Classification (‘SVC’)\n",
    "\n",
    "## Ансамблевые алгоритмы<a class=\"anchor\" id=\"7-3\"></a>\n",
    "- Bagging (классификация) / Bagging Classifier (‘BG’) (Bagging = Bootstrap aggregating)\n",
    "- Случайный лес (классификация) / Random Forest Classifier (‘RF’)\n",
    "- Экстра-деревья (классификация) / Extra Trees Classifier (‘ET’)\n",
    "- AdaBoost (классификация) / AdaBoost Classifier (‘AB’) (AdaBoost = Adaptive Boosting)\n",
    "- Градиентный boosting (классификация) / Gradient Boosting Classifier (‘GB’)\n",
    "\n",
    "[Развернутый пример](https://habr.com/ru/post/475552/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Настройка параметров оценивания алгоритма\n",
    "seed = 7\n",
    "num_folds = 10\n",
    "n_estimators = 100\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LSVC', LinearSVC()))\n",
    "models.append(('SVC', SVC()))\n",
    "models.append(('BG', BaggingClassifier(n_estimators=n_estimators)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=n_estimators)))\n",
    "models.append(('ET', ExtraTreesClassifier(n_estimators=n_estimators)))\n",
    "models.append(('AB', AdaBoostClassifier(n_estimators=n_estimators, algorithm='SAMME')))\n",
    "models.append(('GB', GradientBoostingClassifier(n_estimators=n_estimators)))\n",
    "\n",
    "#Оценивание эффективности выполнения каждого алгоритма\n",
    "scores = []\n",
    "names = []\n",
    "results = []\n",
    "predictions = []\n",
    "msg_row = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    names.append(name)\n",
    "    results.append(cv_results)\n",
    "    m_fit = model.fit(X_train, y_train)\n",
    "    m_predict = model.predict(X_test)\n",
    "    predictions.append(m_predict)\n",
    "    m_score = model.score(X_test, y_test)\n",
    "    scores.append(m_score)\n",
    "    f1=f1_score(y_test, model.predict(X_test))\n",
    "    msg = \"%s: train = %.3f (%.3f) / test = %.3f / f1=%.3f\" % (name, cv_results.mean(), cv_results.std(), m_score, f1)\n",
    "    msg_row.append(msg)\n",
    "    print(msg)\n",
    "    \n",
    "#Диаграмма размаха («ящик с усами»)\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Сравнение результатов выполнения алгоритмов')\n",
    "ax = fig.add_subplot(111)\n",
    "red_square = dict(markerfacecolor='r', marker='s')\n",
    "pyplot.boxplot(results, flierprops=red_square)\n",
    "ax.set_xticklabels(names, rotation=45)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача линейной регрессии<a class=\"anchor\" id=\"8\"></a>\n",
    "\n",
    "Для решения проблемы прогнозирования задействуем следующие алгоритмы:\n",
    "\n",
    "## Линейные алгоритмы<a class=\"anchor\" id=\"8-1\"></a>\n",
    "\n",
    "- Линейная регрессия / Linear Regression (‘LR’)\n",
    "- Гребневая регрессия (ридж-регрессия) / Ridge Regression (‘R’)\n",
    "- Лассо-регрессия (от англ. LASSO — Least Absolute Shrinkage and Selection Operator) / Lasso Regression (‘L’)\n",
    "- Метод регрессии «Эластичная сеть» / Elastic Net Regression (‘ELN’)\n",
    "- Метод наименьших углов / Least Angle Regression (LARS) (‘LARS’)\n",
    "- Байесовская гребневая регрессия / Bayesian ridge regression (‘BR’)\n",
    "\n",
    "## Нелинейные алгоритмы<a class=\"anchor\" id=\"8-2\"></a>\n",
    "\n",
    "- Метод k-ближайших соседей (регрессия) / k-nearest neighbors regressor (‘KNR’)\n",
    "- Деревья регрессии / Decision Tree Regressor (‘DTR’)\n",
    "- Линейный метод опорных векторов (регрессия) / Linear Support Vector Machine – Regression / (‘LSVR’)\n",
    "- Метод опорных векторов (регрессия) / Epsilon-Support Vector Regression (‘SVR’)\n",
    "\n",
    "## Ансамблевые алгоритмы<a class=\"anchor\" id=\"8-3\"></a>\n",
    "\n",
    "- AdaBoost (регрессия) / AdaBoost Regressor (‘ABR’) (AdaBoost = Adaptive Boosting)\n",
    "- Bagging (регрессия) / Bagging Regressor (‘BR’) (Bagging = Bootstrap aggregating)\n",
    "- Экстра-деревья (регрессия) / Extra Trees Regressor (‘ETR’)\n",
    "- Градиентный boosting (регрессия) / Gradient Boosting Regressor (‘GBR’)\n",
    "- Случайный лес (регрессия) / Random Forest Classifier (‘RFR’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_r=['Код дороги', 'Тип виновного предприятия', 'Сторонняя организация',\n",
    "       'Вид работ', 'Время расстройства маневровой работы', 'Регион',\n",
    "       'Погибло всего', 'Номер пути', 'Время полного перерыва движения',\n",
    "       'День недели', 'Общее время задержки', 'Ранено тяжело',\n",
    "       'Признак столкновения', 'Километр', 'Признак схода', 'Ранено легко',\n",
    "       'Время суток', 'Месяц события',\n",
    "       'Количество задержанных поездов']\n",
    "\n",
    "Y=data['Итоговый суммарный ущерб (тыс.руб.)']\n",
    "X=data[col_r]\n",
    "from sklearn.model_selection import train_test_split\n",
    "#разделим набор на тренировочный и тестовый\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LarsCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import Lars\n",
    "from matplotlib import pyplot\n",
    "\n",
    "num_folds = 15\n",
    "n_iter = 1000\n",
    "n_estimators = 100\n",
    "scoring = 'r2'\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('R', Ridge()))\n",
    "models.append(('L', Lasso()))\n",
    "models.append(('ELN', ElasticNet()))\n",
    "models.append(('LARS', Lars()))\n",
    "models.append(('BR', BayesianRidge(n_iter=n_iter)))\n",
    "models.append(('KNR', KNeighborsRegressor()))\n",
    "models.append(('DTR', DecisionTreeRegressor()))\n",
    "models.append(('LSVR', LinearSVR()))\n",
    "models.append(('SVR', SVR()))\n",
    "models.append(('ABR', AdaBoostRegressor(n_estimators=n_estimators)))\n",
    "models.append(('BR', BaggingRegressor(n_estimators=n_estimators)))\n",
    "models.append(('ETR', ExtraTreesRegressor(n_estimators=n_estimators)))\n",
    "models.append(('GBR', GradientBoostingRegressor(n_estimators=n_estimators)))\n",
    "models.append(('RFR', RandomForestRegressor(n_estimators=n_estimators)))\n",
    "\n",
    "#Оценивание эффективности выполнения каждого алгоритма\n",
    "scores = []\n",
    "names = []\n",
    "results = []\n",
    "predictions = []\n",
    "msg_row = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    names.append(name)\n",
    "    results.append(cv_results)\n",
    "    m_fit = model.fit(X_train, y_train)\n",
    "    m_predict = model.predict(X_test)\n",
    "    predictions.append(m_predict)\n",
    "    m_score = model.score(X_test, y_test)\n",
    "    scores.append(m_score)\n",
    "    msg = \"%s: train = %.3f (%.3f) / test = %.3f\" % (name, cv_results.mean(), cv_results.std(), m_score)\n",
    "    msg_row.append(msg)\n",
    "    print(msg)\n",
    "    \n",
    "#Диаграмма размаха («ящик с усами»)\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Сравнение результатов выполнения алгоритмов')\n",
    "ax = fig.add_subplot(111)\n",
    "red_square = dict(markerfacecolor='r', marker='s')\n",
    "pyplot.boxplot(results, flierprops=red_square)\n",
    "ax.set_xticklabels(names, rotation=45)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
